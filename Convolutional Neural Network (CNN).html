<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>TP2-Notebook</title><script src="https://unpkg.com/jupyter-js-widgets@2.0.*/dist/embed.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 style="text-align:center">Deep Learning   </h1>
<h1 style="text-align:center"> Lab Session 2 - 3 Hours </h1>
<h1 style="text-align:center"> Convolutional Neural Network (CNN) for Handwritten Digits Recognition</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Student 1:</b> Dounia Boughalem
<b> Student 2:</b> Faycal Fassi-Fehri</p>
<p>The aim of this session is to practice with Convolutional Neural Networks. Answers and experiments should be made by groups of one or two students. Each group should fill and run appropriate notebook cells.</p>
<p>Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an pdf document using print as PDF (Ctrl+P). Do not forget to run all your cells before generating your final report and do not forget to include the names of all participants in the group. The lab session should be completed by May 29th 2017.</p>
<p>Send you pdf file to benoit.huet@eurecom.fr and olfa.ben-ahmed@eurecom.fr using <strong>[DeepLearning_lab2]</strong> as Subject of your email.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introduction">Introduction<a class="anchor-link" href="#Introduction">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the last Lab Session, you built a Multilayer Perceptron for recognizing hand-written digits from the MNIST data-set. The best achieved accuracy on testing data was about 97%.  Can  you do better than these results using a deep CNN ?
In this Lab Session, you will build, train and optimize in TensorFlow one of the early Convolutional Neural Networks:  <strong>LeNet-5</strong> to go to  more than 99% of accuracy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Load-MNIST-Data-in-TensorFlow">Load MNIST Data in TensorFlow<a class="anchor-link" href="#Load-MNIST-Data-in-TensorFlow">&#182;</a></h1><p>Run the cell above to load the MNIST data that comes  with TensorFlow. You will use this data in <strong>Section 1</strong> and <strong>Section 2</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">&quot;MNIST_data/&quot;</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span>           <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">images</span><span class="p">,</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">labels</span>
<span class="n">X_validation</span><span class="p">,</span> <span class="n">y_validation</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">images</span><span class="p">,</span> <span class="n">mnist</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">labels</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span>             <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">,</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Image Shape: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Training Set:   {} samples&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Validation Set: {} samples&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_validation</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Test Set:       {} samples&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
Image Shape: (784,)
Training Set:   55000 samples
Validation Set: 5000 samples
Test Set:       10000 samples
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Section-1-:-My-First-Model-in-TensorFlow">Section 1 : My First Model in TensorFlow<a class="anchor-link" href="#Section-1-:-My-First-Model-in-TensorFlow">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before starting with CNN, let's train and test in TensorFlow the example :
<strong>y=softmax(Wx+b)</strong> seen in the DeepLearing course last week.</p>
<p>This model reaches an accuracy of about 92 %.
You will also learn how to launch the tensorBoard <a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard">https://www.tensorflow.org/get_started/summaries_and_tensorboard</a> to  visualize the computation graph, statistics and learning curves.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Part 1 </b> : Read carefully the code in the cell below. Run it to perform training.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>


<span class="c1">#STEP 1</span>

<span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="c1"># Construct model and encapsulating all ops into scopes, making Tensorboard&#39;s Graph visualization more convenient</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="c1"># Softmax</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># Gradient Descent</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">):</span>
    <span class="c1"># Accuracy</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="c1"># Initializing the variables</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
<span class="c1"># Create a summary to monitor cost tensor</span>
<span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
<span class="c1"># Create a summary to monitor accuracy tensor</span>
<span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
<span class="c1"># Merge all summaries into a single op</span>
<span class="n">merged_summary_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>


<span class="c1">#STEP 2 </span>


<span class="c1"># Launch the graph for training</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="c1"># op to write logs to Tensorboard</span>
    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">logs_path</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">())</span>
    <span class="c1"># Training cycle</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_epochs</span><span class="p">):</span>
        <span class="n">avg_cost</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">total_batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_examples</span><span class="o">/</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># Loop over all batches</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_batch</span><span class="p">):</span>
            <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="c1"># Run optimization op (backprop), cost op (to get loss value)</span>
            <span class="c1"># and summary nodes</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">summary</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">merged_summary_op</span><span class="p">],</span>
                                     <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">batch_ys</span><span class="p">})</span>
            <span class="c1"># Write logs at every iteration</span>
            <span class="n">summary_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">*</span> <span class="n">total_batch</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>
            <span class="c1"># Compute average loss</span>
            <span class="n">avg_cost</span> <span class="o">+=</span> <span class="n">c</span> <span class="o">/</span> <span class="n">total_batch</span>
        <span class="c1"># Display logs per epoch step</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Epoch: &quot;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%02d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;  =====&gt; Loss=&quot;</span><span class="p">,</span> <span class="s2">&quot;{:.9f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_cost</span><span class="p">))</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Optimization Finished!&quot;</span><span class="p">)</span>

    <span class="c1"># Test model</span>
    <span class="c1"># Calculate accuracy</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="o">.</span><span class="n">eval</span><span class="p">({</span><span class="n">x</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span><span class="p">}))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch:  01   =====&gt; Loss= 1.286880517
Epoch:  02   =====&gt; Loss= 0.731972858
Epoch:  03   =====&gt; Loss= 0.600073437
Epoch:  04   =====&gt; Loss= 0.536622056
Epoch:  05   =====&gt; Loss= 0.497807679
Epoch:  06   =====&gt; Loss= 0.470959418
Epoch:  07   =====&gt; Loss= 0.451343043
Epoch:  08   =====&gt; Loss= 0.435935547
Epoch:  09   =====&gt; Loss= 0.423552829
Epoch:  10   =====&gt; Loss= 0.413048692
Epoch:  11   =====&gt; Loss= 0.404532150
Epoch:  12   =====&gt; Loss= 0.396799336
Epoch:  13   =====&gt; Loss= 0.390114282
Epoch:  14   =====&gt; Loss= 0.384426002
Epoch:  15   =====&gt; Loss= 0.379342771
Epoch:  16   =====&gt; Loss= 0.374710613
Epoch:  17   =====&gt; Loss= 0.370302257
Epoch:  18   =====&gt; Loss= 0.366418708
Epoch:  19   =====&gt; Loss= 0.362688332
Epoch:  20   =====&gt; Loss= 0.359563804
Epoch:  21   =====&gt; Loss= 0.356634596
Epoch:  22   =====&gt; Loss= 0.353643236
Epoch:  23   =====&gt; Loss= 0.351197322
Epoch:  24   =====&gt; Loss= 0.348525737
Epoch:  25   =====&gt; Loss= 0.346346418
Epoch:  26   =====&gt; Loss= 0.344509799
Epoch:  27   =====&gt; Loss= 0.342008740
Epoch:  28   =====&gt; Loss= 0.340397068
Epoch:  29   =====&gt; Loss= 0.338575198
Epoch:  30   =====&gt; Loss= 0.336579700
Epoch:  31   =====&gt; Loss= 0.335050470
Epoch:  32   =====&gt; Loss= 0.333262188
Epoch:  33   =====&gt; Loss= 0.332064762
Epoch:  34   =====&gt; Loss= 0.330590773
Epoch:  35   =====&gt; Loss= 0.328922253
Epoch:  36   =====&gt; Loss= 0.327590144
Epoch:  37   =====&gt; Loss= 0.326492495
Epoch:  38   =====&gt; Loss= 0.325545454
Epoch:  39   =====&gt; Loss= 0.323938292
Epoch:  40   =====&gt; Loss= 0.322959157
Epoch:  41   =====&gt; Loss= 0.321641395
Epoch:  42   =====&gt; Loss= 0.320593472
Epoch:  43   =====&gt; Loss= 0.319858140
Epoch:  44   =====&gt; Loss= 0.318728267
Epoch:  45   =====&gt; Loss= 0.317849886
Epoch:  46   =====&gt; Loss= 0.317211604
Epoch:  47   =====&gt; Loss= 0.316299121
Epoch:  48   =====&gt; Loss= 0.315535728
Epoch:  49   =====&gt; Loss= 0.314491911
Epoch:  50   =====&gt; Loss= 0.313661881
Epoch:  51   =====&gt; Loss= 0.312703442
Epoch:  52   =====&gt; Loss= 0.312287142
Epoch:  53   =====&gt; Loss= 0.311521165
Epoch:  54   =====&gt; Loss= 0.310555045
Epoch:  55   =====&gt; Loss= 0.310166852
Epoch:  56   =====&gt; Loss= 0.309220693
Epoch:  57   =====&gt; Loss= 0.308312704
Epoch:  58   =====&gt; Loss= 0.307853764
Epoch:  59   =====&gt; Loss= 0.307291760
Epoch:  60   =====&gt; Loss= 0.306693834
Epoch:  61   =====&gt; Loss= 0.305978786
Epoch:  62   =====&gt; Loss= 0.305361913
Epoch:  63   =====&gt; Loss= 0.304938233
Epoch:  64   =====&gt; Loss= 0.304549100
Epoch:  65   =====&gt; Loss= 0.303640487
Epoch:  66   =====&gt; Loss= 0.303304098
Epoch:  67   =====&gt; Loss= 0.302867644
Epoch:  68   =====&gt; Loss= 0.302131963
Epoch:  69   =====&gt; Loss= 0.301509871
Epoch:  70   =====&gt; Loss= 0.301352131
Epoch:  71   =====&gt; Loss= 0.300760030
Epoch:  72   =====&gt; Loss= 0.300446450
Epoch:  73   =====&gt; Loss= 0.299782330
Epoch:  74   =====&gt; Loss= 0.299458369
Epoch:  75   =====&gt; Loss= 0.299219690
Epoch:  76   =====&gt; Loss= 0.298567939
Epoch:  77   =====&gt; Loss= 0.298194959
Epoch:  78   =====&gt; Loss= 0.297762068
Epoch:  79   =====&gt; Loss= 0.297131069
Epoch:  80   =====&gt; Loss= 0.296779315
Epoch:  81   =====&gt; Loss= 0.296552829
Epoch:  82   =====&gt; Loss= 0.296084488
Epoch:  83   =====&gt; Loss= 0.295722758
Epoch:  84   =====&gt; Loss= 0.295438908
Epoch:  85   =====&gt; Loss= 0.294558807
Epoch:  86   =====&gt; Loss= 0.294719684
Epoch:  87   =====&gt; Loss= 0.293898353
Epoch:  88   =====&gt; Loss= 0.293676612
Epoch:  89   =====&gt; Loss= 0.293226857
Epoch:  90   =====&gt; Loss= 0.293119008
Epoch:  91   =====&gt; Loss= 0.292888028
Epoch:  92   =====&gt; Loss= 0.292535561
Epoch:  93   =====&gt; Loss= 0.292170377
Epoch:  94   =====&gt; Loss= 0.291808015
Epoch:  95   =====&gt; Loss= 0.291720729
Epoch:  96   =====&gt; Loss= 0.291370209
Epoch:  97   =====&gt; Loss= 0.291054540
Epoch:  98   =====&gt; Loss= 0.290816135
Epoch:  99   =====&gt; Loss= 0.290273524
Epoch:  100   =====&gt; Loss= 0.290159381
Optimization Finished!
Accuracy: 0.9205
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Part 2  </b>: Using Tensorboard, we can  now visualize the created graph, giving you an overview of your architecture and how all of the major components  are connected. You can also see and analyse the learning curves.</p>
<p>To launch tensorBoard:</p>
<ul>
<li>Go to the <strong>TP2</strong> folder, </li>
<li>Open a Terminal and run the command line <strong>"tensorboard --logdir=log_files/"</strong>, it will generate an http link ,ex <a href="http://666.6.6.6:6006">http://666.6.6.6:6006</a>,</li>
<li>Copy this  link into your web browser </li>
</ul>
<p>Enjoy It !!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Section-2-:-The-99%-MNIST-Challenge-!">Section 2 : The 99% MNIST Challenge !<a class="anchor-link" href="#Section-2-:-The-99%-MNIST-Challenge-!">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Part 1 </b> : LeNet5 implementation</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One you are now familar with <strong>tensorFlow</strong> and <strong>tensorBoard</strong>, you are in this section to build, train and test the baseline <a href="http://yann.lecun.com/exdb/lenet/">LeNet-5</a>  model for the MNIST digits recognition problem.</p>
<p>In more advanced step you will make some optimizations to get more than 99% of accuracy. The best model can get to over 99.7% accuracy!</p>
<p>For more information, have a look at this list of results : <a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html">http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>&lt;img src="lenet.png",width="800" height="600" align="center"&gt;</p>
<center><span>Figure 1: Lenet 5 </span></center><p>The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.</p>
<hr>
<p><strong>Layer 1: Convolutional.</strong> The output shape should be 28x28x6 <strong>Activation.</strong> sigmoid <strong>Pooling.</strong> The output shape should be 14x14x6.</p>
<p><strong>Layer 2: Convolutional.</strong> The output shape should be 10x10x16. <strong>Activation.</strong> sigmoid <strong>Pooling.</strong> The output shape should be 5x5x16.</p>
<p><strong>Flatten.</strong> Flatten the output shape of the final pooling layer such that it's 1D instead of 3D.  You may need to use *<em>flatten</em>  from tensorflow.contrib.layers import flatten</p>
<p><strong>Layer 3: Fully Connected.</strong> This should have 120 outputs. <strong>Activation.</strong> sigmoid</p>
<p><strong>Layer 4: Fully Connected.</strong> This should have 84 outputs. <strong>Activation.</strong> sigmoid</p>
<p><strong>Layer 5: Fully Connected.</strong> This should have 10 outputs. <strong>Activation.</strong> softmax</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Question 2.1.1 </b>  Implement the Neural Network architecture described above.
For that, your will use classes and functions from  <a href="https://www.tensorflow.org/api_docs/python/tf/nn">https://www.tensorflow.org/api_docs/python/tf/nn</a>.</p>
<p>We give you some helper functions for weigths and bias initilization. Also you can refer to section 1.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#Helper functions  for weigths and bias initilization </span>



<span class="k">def</span> <span class="nf">weight_variable</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
  <span class="n">initial</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">bias_variable</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
  <span class="n">initial</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.contrib.layers</span> <span class="kn">import</span> <span class="n">flatten</span>

<span class="k">def</span> <span class="nf">LeNet5_Model</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>    
    <span class="c1"># your inmplementation goes here</span>
    <span class="c1">#Layer 1: Convolutional</span>
    <span class="n">layer1_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
    <span class="n">layer1_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">6</span><span class="p">,))</span>
    <span class="n">data2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="n">layer1_weights</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">layer1_bias</span>
    <span class="c1">#Activation. sigmoid</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">conv1</span><span class="p">)</span>
    <span class="c1">#Pooling</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">conv1</span> <span class="p">,</span><span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    
    
    <span class="c1">#Layer 2: Convolutional</span>
    <span class="n">layer2_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">16</span><span class="p">))</span>
    <span class="n">layer2_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">16</span><span class="p">,))</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="n">layer2_weights</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;VALID&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">layer2_bias</span>
    <span class="c1">#Activation. sigmoid</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>
    <span class="c1">#Pooling</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">conv2</span> <span class="p">,</span><span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    
    <span class="c1">#Flatten</span>
    <span class="n">conv_flat</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>
    
    <span class="c1">#Layer 3: Fully Connected</span>
    <span class="n">layer3_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">400</span><span class="p">,</span> <span class="mi">120</span><span class="p">))</span>
    <span class="n">layer3_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">120</span><span class="p">,))</span>
    <span class="n">layer3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span><span class="n">conv_flat</span><span class="p">,</span><span class="n">layer3_weights</span><span class="p">,</span><span class="n">layer3_bias</span><span class="p">)</span>

    <span class="c1">#Activation. sigmoid</span>
    
    <span class="n">layer3_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">layer3</span><span class="p">)</span>
    
    <span class="c1">#Layer 4: Fully Connected</span>
    <span class="n">layer4_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">))</span>
    <span class="n">layer4_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">84</span><span class="p">,))</span>
    <span class="n">layer4</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span> <span class="n">layer3_out</span><span class="p">,</span><span class="n">layer4_weights</span><span class="p">,</span><span class="n">layer4_bias</span><span class="p">)</span>

    <span class="c1">#Activation. sigmoid</span>
    
    <span class="n">layer4_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">layer4</span><span class="p">)</span>
    
    <span class="c1">#Layer 5: Fully Connected</span>
    <span class="n">layer5_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">layer5_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">10</span><span class="p">,))</span>
    <span class="n">layer5</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span> <span class="n">layer4_out</span><span class="p">,</span><span class="n">layer5_weights</span><span class="p">,</span><span class="n">layer5_bias</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">layer5</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">model</span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Question 2.1.2. </b>  Calculate the number of parameters of this model</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Layer 1: Convolutional</p>
<p>Weights = 5*5*1*6 = 150  </p>
<p> Bias = 6 </p><p>Layer 2: Convolutional.</p>
<p>Weights = 2400  </p>
<p> Bias =16 </p><p>Layer 3: Fully Connected.</p>
<p>Weights = 48000  </p>
<p> Bias = 120 </p><p>Layer 4: Fully Connected.</p>
<p>Weights = 10080  </p>
<p> Bias = 84 </p><p>Layer 5: Fully Connected.</p>
<p>Weights = 840  </p>
<p> Bias = 10 </p><h2 id="The-number-of-parameters-of-this-model-is-equal-to-:-61706">The number of parameters of this model is equal to : 61706<a class="anchor-link" href="#The-number-of-parameters-of-this-model-is-equal-to-:-61706">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Question 2.1.3. </b>  Start the training with the parameters cited below:</p>

<pre><code> Learning rate =0.1
 Loss Fucntion : Cross entropy
 Optimisateur: SGD
 Number of training iterations= 10000
 The batch size =128</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>


<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># Gradient Descent</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Question 2.1.4. </b>  Implement the evaluation function for accuracy computation</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy_operation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">):</span>
    <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
    <span class="n">total_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_session</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">X_data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">y_data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy_operation</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">batch_y</span><span class="p">})</span>
        <span class="n">total_accuracy</span> <span class="o">+=</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">total_accuracy</span> <span class="o">/</span> <span class="n">num_examples</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Question 2.1.5. </b>  Implement training pipeline and run the training data through it to train the model.</p>
<ul>
<li>Before each epoch, shuffle the training set. </li>
<li>Print the loss per mini batch and the training/validation accuracy per epoch. (Display results every 100 epochs)</li>
<li>Save the model after training</li>
<li>Print after training the final testing accuracy </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">import</span> <span class="nn">time</span>



<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">file_save</span><span class="p">):</span>

        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">training_acc</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">validation_acc</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="c1"># Initializing the variables</span>
        <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
        <span class="c1"># Create a summary to monitor cost tensor</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
        <span class="c1"># Create a summary to monitor accuracy tensor</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;Traning_Accuracy&quot;</span><span class="p">,</span> <span class="n">training_acc</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;Validation_Accuracy&quot;</span><span class="p">,</span> <span class="n">validation_acc</span><span class="p">)</span>
        <span class="c1"># Merge all summaries into a single op</span>
        <span class="n">merged_summary_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
        

        
        <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;Start Training!&quot;</span><span class="p">)</span>
        
        <span class="c1"># Launch the graph for training</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
            <span class="c1"># op to write logs to Tensorboard</span>
            <span class="c1"># Training cycle</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_epochs</span><span class="p">):</span>
                <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
                <span class="n">avg_cost</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
                <span class="n">total_batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_examples</span><span class="o">/</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="c1"># Loop over all batches</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">num_examples</span><span class="p">,</span><span class="n">batch_size</span><span class="p">):</span>
                    <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                    <span class="c1"># Run optimization op (backprop), cost op (to get loss value)</span>
                    <span class="c1"># and summary nodes</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">summary</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">merged_summary_op</span><span class="p">],</span>
                                             <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">batch_ys</span><span class="p">})</span>
                    <span class="c1"># Write logs at every iteration</span>
                    <span class="c1"># Compute average loss</span>
                    <span class="n">avg_cost</span> <span class="o">+=</span> <span class="n">c</span> <span class="o">/</span> <span class="n">total_batch</span>
                <span class="c1"># Display logs per epoch step</span>
                <span class="n">training_acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
                <span class="n">validation_acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Epoch: &quot;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%02d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;  =====&gt; Loss=&quot;</span><span class="p">,</span> <span class="s2">&quot;{:.9f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_cost</span><span class="p">))</span>
                    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: Training :&quot;</span><span class="p">,</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span>
                    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: Validation :&quot;</span><span class="p">,</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">))</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: Test :&quot;</span><span class="p">,</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>
            <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;Training Finished!&quot;</span><span class="p">)</span>
            <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">file_save</span><span class="p">)</span>
        <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training time =&#39;</span><span class="p">,</span><span class="n">training_time</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Question 2.1.6 </b> : Use tensorBoard to visualise and save the LeNet5 Graph and all learning curves. 
Save all obtained figures in the folder <strong>"TP2/MNIST_99_Challenge_Figures"</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span> <span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;01&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312420604&#39;)
(&#39;Accuracy: Training :&#39;, 0.1039090908982537)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;02&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311368896&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818170980979)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;03&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310909491&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490909090909086)
(&#39;Accuracy: Validation :&#39;, 0.107)
(&#39;Epoch: &#39;, &#39;04&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310147095&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454545450210569)
(&#39;Accuracy: Validation :&#39;, 0.097600000000000006)
(&#39;Epoch: &#39;, &#39;05&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.309549134&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454545456712895)
(&#39;Accuracy: Validation :&#39;, 0.097600000000000006)
(&#39;Epoch: &#39;, &#39;06&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.309062473&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454545454)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;07&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.308141752&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545455195687)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;08&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.306742659&#39;)
(&#39;Accuracy: Training :&#39;, 0.11814545454111966)
(&#39;Accuracy: Validation :&#39;, 0.11600000000000001)
(&#39;Epoch: &#39;, &#39;09&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.303634831&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454437082)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.292301753&#39;)
(&#39;Accuracy: Training :&#39;, 0.11959999999891628)
(&#39;Accuracy: Validation :&#39;, 0.1212)
(&#39;Epoch: &#39;, &#39;11&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.168025609&#39;)
(&#39;Accuracy: Training :&#39;, 0.31181818181167947)
(&#39;Accuracy: Validation :&#39;, 0.314)
(&#39;Epoch: &#39;, &#39;12&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.711051043&#39;)
(&#39;Accuracy: Training :&#39;, 0.55640000003467904)
(&#39;Accuracy: Validation :&#39;, 0.56740000000000002)
(&#39;Epoch: &#39;, &#39;13&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.118027190&#39;)
(&#39;Accuracy: Training :&#39;, 0.74434545458013357)
(&#39;Accuracy: Validation :&#39;, 0.74639999999999995)
(&#39;Epoch: &#39;, &#39;14&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.687542840&#39;)
(&#39;Accuracy: Training :&#39;, 0.830654545471885)
(&#39;Accuracy: Validation :&#39;, 0.83840000000000003)
(&#39;Epoch: &#39;, &#39;15&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.477052252&#39;)
(&#39;Accuracy: Training :&#39;, 0.88643636364503342)
(&#39;Accuracy: Validation :&#39;, 0.88780000000000003)
(&#39;Epoch: &#39;, &#39;16&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.356231484&#39;)
(&#39;Accuracy: Training :&#39;, 0.90861818178350273)
(&#39;Accuracy: Validation :&#39;, 0.91559999999999997)
(&#39;Epoch: &#39;, &#39;17&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.287009686&#39;)
(&#39;Accuracy: Training :&#39;, 0.9225636363723061)
(&#39;Accuracy: Validation :&#39;, 0.92859999999999998)
(&#39;Epoch: &#39;, &#39;18&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.244644831&#39;)
(&#39;Accuracy: Training :&#39;, 0.93379999999133023)
(&#39;Accuracy: Validation :&#39;, 0.93959999999999999)
(&#39;Epoch: &#39;, &#39;19&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.214369351&#39;)
(&#39;Accuracy: Training :&#39;, 0.94003636359301479)
(&#39;Accuracy: Validation :&#39;, 0.94420000000000004)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.192372784&#39;)
(&#39;Accuracy: Training :&#39;, 0.94689090911691842)
(&#39;Accuracy: Validation :&#39;, 0.95179999999999998)
(&#39;Epoch: &#39;, &#39;21&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.174087866&#39;)
(&#39;Accuracy: Training :&#39;, 0.95114545453678478)
(&#39;Accuracy: Validation :&#39;, 0.95640000000000003)
(&#39;Epoch: &#39;, &#39;22&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.159546758&#39;)
(&#39;Accuracy: Training :&#39;, 0.95472727277062153)
(&#39;Accuracy: Validation :&#39;, 0.95960000000000001)
(&#39;Epoch: &#39;, &#39;23&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.147070535&#39;)
(&#39;Accuracy: Training :&#39;, 0.95821818180951202)
(&#39;Accuracy: Validation :&#39;, 0.96099999999999997)
(&#39;Epoch: &#39;, &#39;24&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.136931728&#39;)
(&#39;Accuracy: Training :&#39;, 0.9614181818355213)
(&#39;Accuracy: Validation :&#39;, 0.96579999999999999)
(&#39;Epoch: &#39;, &#39;25&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.128436560&#39;)
(&#39;Accuracy: Training :&#39;, 0.96396363635496662)
(&#39;Accuracy: Validation :&#39;, 0.96740000000000004)
(&#39;Epoch: &#39;, &#39;26&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.120788647&#39;)
(&#39;Accuracy: Training :&#39;, 0.96499999999133024)
(&#39;Accuracy: Validation :&#39;, 0.96919999999999995)
(&#39;Epoch: &#39;, &#39;27&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.114314941&#39;)
(&#39;Accuracy: Training :&#39;, 0.96754545450210572)
(&#39;Accuracy: Validation :&#39;, 0.97119999999999995)
(&#39;Epoch: &#39;, &#39;28&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.108275497&#39;)
(&#39;Accuracy: Training :&#39;, 0.96829090909090909)
(&#39;Accuracy: Validation :&#39;, 0.97219999999999995)
(&#39;Epoch: &#39;, &#39;29&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.103968992&#39;)
(&#39;Accuracy: Training :&#39;, 0.97027272722937841)
(&#39;Accuracy: Validation :&#39;, 0.97219999999999995)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.099360372&#39;)
(&#39;Accuracy: Training :&#39;, 0.97107272727272731)
(&#39;Accuracy: Validation :&#39;, 0.9738)
(&#39;Epoch: &#39;, &#39;31&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.095626256&#39;)
(&#39;Accuracy: Training :&#39;, 0.97252727274461226)
(&#39;Accuracy: Validation :&#39;, 0.97399999999999998)
(&#39;Epoch: &#39;, &#39;32&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.092259873&#39;)
(&#39;Accuracy: Training :&#39;, 0.97352727276195183)
(&#39;Accuracy: Validation :&#39;, 0.97560000000000002)
(&#39;Epoch: &#39;, &#39;33&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.089132739&#39;)
(&#39;Accuracy: Training :&#39;, 0.97412727270126342)
(&#39;Accuracy: Validation :&#39;, 0.97540000000000004)
(&#39;Epoch: &#39;, &#39;34&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.086126353&#39;)
(&#39;Accuracy: Training :&#39;, 0.97514545458013357)
(&#39;Accuracy: Validation :&#39;, 0.97719999999999996)
(&#39;Epoch: &#39;, &#39;35&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.083668036&#39;)
(&#39;Accuracy: Training :&#39;, 0.97550909086574211)
(&#39;Accuracy: Validation :&#39;, 0.97740000000000005)
(&#39;Epoch: &#39;, &#39;36&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.081267221&#39;)
(&#39;Accuracy: Training :&#39;, 0.97576363632028751)
(&#39;Accuracy: Validation :&#39;, 0.97819999999999996)
(&#39;Epoch: &#39;, &#39;37&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.078870353&#39;)
(&#39;Accuracy: Training :&#39;, 0.97541818183552131)
(&#39;Accuracy: Validation :&#39;, 0.97760000000000002)
(&#39;Epoch: &#39;, &#39;38&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.076815005&#39;)
(&#39;Accuracy: Training :&#39;, 0.97756363638097588)
(&#39;Accuracy: Validation :&#39;, 0.97860000000000003)
(&#39;Epoch: &#39;, &#39;39&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.074877414&#39;)
(&#39;Accuracy: Training :&#39;, 0.9774363636710427)
(&#39;Accuracy: Validation :&#39;, 0.97899999999999998)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.073156681&#39;)
(&#39;Accuracy: Training :&#39;, 0.97872727274461224)
(&#39;Accuracy: Validation :&#39;, 0.9798)
(&#39;Epoch: &#39;, &#39;41&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.071186975&#39;)
(&#39;Accuracy: Training :&#39;, 0.97941818185286089)
(&#39;Accuracy: Validation :&#39;, 0.97899999999999998)
(&#39;Epoch: &#39;, &#39;42&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.069865072&#39;)
(&#39;Accuracy: Training :&#39;, 0.97979999995665112)
(&#39;Accuracy: Validation :&#39;, 0.9798)
(&#39;Epoch: &#39;, &#39;43&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.068479754&#39;)
(&#39;Accuracy: Training :&#39;, 0.98030909094376995)
(&#39;Accuracy: Validation :&#39;, 0.98019999999999996)
(&#39;Epoch: &#39;, &#39;44&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.066919881&#39;)
(&#39;Accuracy: Training :&#39;, 0.97930909086574203)
(&#39;Accuracy: Validation :&#39;, 0.98019999999999996)
(&#39;Epoch: &#39;, &#39;45&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.065620423&#39;)
(&#39;Accuracy: Training :&#39;, 0.98007272727272732)
(&#39;Accuracy: Validation :&#39;, 0.97960000000000003)
(&#39;Epoch: &#39;, &#39;46&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.064461467&#39;)
(&#39;Accuracy: Training :&#39;, 0.98121818181818177)
(&#39;Accuracy: Validation :&#39;, 0.98060000000000003)
(&#39;Epoch: &#39;, &#39;47&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.062886012&#39;)
(&#39;Accuracy: Training :&#39;, 0.98187272730740638)
(&#39;Accuracy: Validation :&#39;, 0.98119999999999996)
(&#39;Epoch: &#39;, &#39;48&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.061970321&#39;)
(&#39;Accuracy: Training :&#39;, 0.98150909086574212)
(&#39;Accuracy: Validation :&#39;, 0.98019999999999996)
(&#39;Epoch: &#39;, &#39;49&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.060705841&#39;)
(&#39;Accuracy: Training :&#39;, 0.98247272729006685)
(&#39;Accuracy: Validation :&#39;, 0.98160000000000003)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.059562749&#39;)
(&#39;Accuracy: Training :&#39;, 0.98110909090909093)
(&#39;Accuracy: Validation :&#39;, 0.97899999999999998)
(&#39;Epoch: &#39;, &#39;51&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.058674784&#39;)
(&#39;Accuracy: Training :&#39;, 0.98300000003467902)
(&#39;Accuracy: Validation :&#39;, 0.98140000000000005)
(&#39;Epoch: &#39;, &#39;52&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.057561856&#39;)
(&#39;Accuracy: Training :&#39;, 0.98321818181818177)
(&#39;Accuracy: Validation :&#39;, 0.98280000000000001)
(&#39;Epoch: &#39;, &#39;53&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.056459228&#39;)
(&#39;Accuracy: Training :&#39;, 0.9832909090909091)
(&#39;Accuracy: Validation :&#39;, 0.98199999999999998)
(&#39;Epoch: &#39;, &#39;54&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.055697545&#39;)
(&#39;Accuracy: Training :&#39;, 0.9837818181558089)
(&#39;Accuracy: Validation :&#39;, 0.98199999999999998)
(&#39;Epoch: &#39;, &#39;55&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.054811164&#39;)
(&#39;Accuracy: Training :&#39;, 0.98390909094376999)
(&#39;Accuracy: Validation :&#39;, 0.98240000000000005)
(&#39;Epoch: &#39;, &#39;56&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.053761623&#39;)
(&#39;Accuracy: Training :&#39;, 0.98445454548922451)
(&#39;Accuracy: Validation :&#39;, 0.98319999999999996)
(&#39;Epoch: &#39;, &#39;57&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.052847398&#39;)
(&#39;Accuracy: Training :&#39;, 0.98421818183552134)
(&#39;Accuracy: Validation :&#39;, 0.98180000000000001)
(&#39;Epoch: &#39;, &#39;58&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.052131482&#39;)
(&#39;Accuracy: Training :&#39;, 0.98456363638097588)
(&#39;Accuracy: Validation :&#39;, 0.98280000000000001)
(&#39;Epoch: &#39;, &#39;59&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.051102827&#39;)
(&#39;Accuracy: Training :&#39;, 0.98498181818181818)
(&#39;Accuracy: Validation :&#39;, 0.98340000000000005)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.050573740&#39;)
(&#39;Accuracy: Training :&#39;, 0.98500000001733956)
(&#39;Accuracy: Validation :&#39;, 0.98340000000000005)
(&#39;Epoch: &#39;, &#39;61&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.049636500&#39;)
(&#39;Accuracy: Training :&#39;, 0.98512727268392386)
(&#39;Accuracy: Validation :&#39;, 0.98480000000000001)
(&#39;Epoch: &#39;, &#39;62&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.048919993&#39;)
(&#39;Accuracy: Training :&#39;, 0.98561818181818184)
(&#39;Accuracy: Validation :&#39;, 0.98380000000000001)
(&#39;Epoch: &#39;, &#39;63&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.048214429&#39;)
(&#39;Accuracy: Training :&#39;, 0.98623636365370315)
(&#39;Accuracy: Validation :&#39;, 0.98399999999999999)
(&#39;Epoch: &#39;, &#39;64&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.047481634&#39;)
(&#39;Accuracy: Training :&#39;, 0.98638181818181814)
(&#39;Accuracy: Validation :&#39;, 0.98440000000000005)
(&#39;Epoch: &#39;, &#39;65&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.046851722&#39;)
(&#39;Accuracy: Training :&#39;, 0.98670909090909087)
(&#39;Accuracy: Validation :&#39;, 0.98460000000000003)
(&#39;Epoch: &#39;, &#39;66&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.046210998&#39;)
(&#39;Accuracy: Training :&#39;, 0.98618181819915773)
(&#39;Accuracy: Validation :&#39;, 0.98340000000000005)
(&#39;Epoch: &#39;, &#39;67&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.045327060&#39;)
(&#39;Accuracy: Training :&#39;, 0.98694545454545457)
(&#39;Accuracy: Validation :&#39;, 0.98460000000000003)
(&#39;Epoch: &#39;, &#39;68&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.044719213&#39;)
(&#39;Accuracy: Training :&#39;, 0.98681818183552139)
(&#39;Accuracy: Validation :&#39;, 0.98499999999999999)
(&#39;Epoch: &#39;, &#39;69&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.044187350&#39;)
(&#39;Accuracy: Training :&#39;, 0.98732727272727272)
(&#39;Accuracy: Validation :&#39;, 0.98440000000000005)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.043660047&#39;)
(&#39;Accuracy: Training :&#39;, 0.98758181819915769)
(&#39;Accuracy: Validation :&#39;, 0.98419999999999996)
(&#39;Epoch: &#39;, &#39;71&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.042967085&#39;)
(&#39;Accuracy: Training :&#39;, 0.98643636363636367)
(&#39;Accuracy: Validation :&#39;, 0.98460000000000003)
(&#39;Epoch: &#39;, &#39;72&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.042516188&#39;)
(&#39;Accuracy: Training :&#39;, 0.98707272729006679)
(&#39;Accuracy: Validation :&#39;, 0.98560000000000003)
(&#39;Epoch: &#39;, &#39;73&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.041891853&#39;)
(&#39;Accuracy: Training :&#39;, 0.98754545458013365)
(&#39;Accuracy: Validation :&#39;, 0.98399999999999999)
(&#39;Epoch: &#39;, &#39;74&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.041330857&#39;)
(&#39;Accuracy: Training :&#39;, 0.98816363639831539)
(&#39;Accuracy: Validation :&#39;, 0.98519999999999996)
(&#39;Epoch: &#39;, &#39;75&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.040839408&#39;)
(&#39;Accuracy: Training :&#39;, 0.98843636365370313)
(&#39;Accuracy: Validation :&#39;, 0.98519999999999996)
(&#39;Epoch: &#39;, &#39;76&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.040361319&#39;)
(&#39;Accuracy: Training :&#39;, 0.98843636363636367)
(&#39;Accuracy: Validation :&#39;, 0.98460000000000003)
(&#39;Epoch: &#39;, &#39;77&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.039775094&#39;)
(&#39;Accuracy: Training :&#39;, 0.9887636363636364)
(&#39;Accuracy: Validation :&#39;, 0.98519999999999996)
(&#39;Epoch: &#39;, &#39;78&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.039176103&#39;)
(&#39;Accuracy: Training :&#39;, 0.98865454545454545)
(&#39;Accuracy: Validation :&#39;, 0.98499999999999999)
(&#39;Epoch: &#39;, &#39;79&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.038545420&#39;)
(&#39;Accuracy: Training :&#39;, 0.98874545454545459)
(&#39;Accuracy: Validation :&#39;, 0.98619999999999997)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.038257931&#39;)
(&#39;Accuracy: Training :&#39;, 0.9891090909264304)
(&#39;Accuracy: Validation :&#39;, 0.98499999999999999)
(&#39;Epoch: &#39;, &#39;81&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.037802100&#39;)
(&#39;Accuracy: Training :&#39;, 0.98936363638097591)
(&#39;Accuracy: Validation :&#39;, 0.98540000000000005)
(&#39;Epoch: &#39;, &#39;82&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.037293030&#39;)
(&#39;Accuracy: Training :&#39;, 0.9890181818181818)
(&#39;Accuracy: Validation :&#39;, 0.98440000000000005)
(&#39;Epoch: &#39;, &#39;83&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.036759595&#39;)
(&#39;Accuracy: Training :&#39;, 0.98974545456279406)
(&#39;Accuracy: Validation :&#39;, 0.98499999999999999)
(&#39;Epoch: &#39;, &#39;84&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.036407027&#39;)
(&#39;Accuracy: Training :&#39;, 0.98969090910824864)
(&#39;Accuracy: Validation :&#39;, 0.98599999999999999)
(&#39;Epoch: &#39;, &#39;85&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.035714185&#39;)
(&#39;Accuracy: Training :&#39;, 0.98958181818181823)
(&#39;Accuracy: Validation :&#39;, 0.98619999999999997)
(&#39;Epoch: &#39;, &#39;86&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.035360628&#39;)
(&#39;Accuracy: Training :&#39;, 0.99005454547188498)
(&#39;Accuracy: Validation :&#39;, 0.98560000000000003)
(&#39;Epoch: &#39;, &#39;87&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.034901416&#39;)
(&#39;Accuracy: Training :&#39;, 0.98972727272727268)
(&#39;Accuracy: Validation :&#39;, 0.98440000000000005)
(&#39;Epoch: &#39;, &#39;88&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.034475087&#39;)
(&#39;Accuracy: Training :&#39;, 0.98936363638097591)
(&#39;Accuracy: Validation :&#39;, 0.98619999999999997)
(&#39;Epoch: &#39;, &#39;89&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.034174022&#39;)
(&#39;Accuracy: Training :&#39;, 0.98969090909090907)
(&#39;Accuracy: Validation :&#39;, 0.98619999999999997)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.033656017&#39;)
(&#39;Accuracy: Training :&#39;, 0.9900363636363636)
(&#39;Accuracy: Validation :&#39;, 0.98540000000000005)
(&#39;Epoch: &#39;, &#39;91&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.033520452&#39;)
(&#39;Accuracy: Training :&#39;, 0.99014545458013359)
(&#39;Accuracy: Validation :&#39;, 0.98619999999999997)
(&#39;Epoch: &#39;, &#39;92&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.032934831&#39;)
(&#39;Accuracy: Training :&#39;, 0.99069090910824864)
(&#39;Accuracy: Validation :&#39;, 0.98619999999999997)
(&#39;Epoch: &#39;, &#39;93&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.032596543&#39;)
(&#39;Accuracy: Training :&#39;, 0.99139999999999995)
(&#39;Accuracy: Validation :&#39;, 0.98660000000000003)
(&#39;Epoch: &#39;, &#39;94&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.032193731&#39;)
(&#39;Accuracy: Training :&#39;, 0.99127272727272731)
(&#39;Accuracy: Validation :&#39;, 0.98680000000000001)
(&#39;Epoch: &#39;, &#39;95&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.031753687&#39;)
(&#39;Accuracy: Training :&#39;, 0.99112727272727275)
(&#39;Accuracy: Validation :&#39;, 0.98660000000000003)
(&#39;Epoch: &#39;, &#39;96&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.031341563&#39;)
(&#39;Accuracy: Training :&#39;, 0.99180000000000001)
(&#39;Accuracy: Validation :&#39;, 0.98640000000000005)
(&#39;Epoch: &#39;, &#39;97&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.031088603&#39;)
(&#39;Accuracy: Training :&#39;, 0.9915090909090909)
(&#39;Accuracy: Validation :&#39;, 0.98719999999999997)
(&#39;Epoch: &#39;, &#39;98&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.030807864&#39;)
(&#39;Accuracy: Training :&#39;, 0.99067272729006683)
(&#39;Accuracy: Validation :&#39;, 0.98660000000000003)
(&#39;Epoch: &#39;, &#39;99&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.030417569&#39;)
(&#39;Accuracy: Training :&#39;, 0.99138181819915772)
(&#39;Accuracy: Validation :&#39;, 0.98740000000000006)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.029946835&#39;)
(&#39;Accuracy: Training :&#39;, 0.99212727272727275)
(&#39;Accuracy: Validation :&#39;, 0.98619999999999997)
(&#39;Accuracy: Test :&#39;, 0.98609999999999998)
Training Finished!
(&#39;Training time =&#39;, 3945.722552061081)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#  insert your obtained figure here </span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we used cross entropy loss function.
We can see that the accuracy obtained for the test sample is high : more than 98 % and that the model doesn't overfit because the accuracy obtained for the validation data is also higher than 98%. It take to the algorithm few iteration to reach 90% of accuracy for the training data (less than 20 iterations)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Part 2 </b> : LeNET 5 Optimization</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Question 2.2.1 </b>  Change the sigmoid function with a Relu :</p>
<ul>
<li>Retrain your network with SGD and AdamOptimizer and then fill the table above  :</li>
</ul>
<table>
<thead><tr>
<th>Optimizer</th>
<th style="text-align:center">Gradient Descent</th>
<th style="text-align:right">AdamOptimizer</th>
</tr>
</thead>
<tbody>
<tr>
<td>Validation Accuracy</td>
<td style="text-align:center">0.990</td>
<td style="text-align:right">0.092</td>
</tr>
<tr>
<td>Testing Accuracy</td>
<td style="text-align:center">0.989</td>
<td style="text-align:right">0.0974</td>
</tr>
<tr>
<td>Training Time</td>
<td style="text-align:center">3889</td>
<td style="text-align:right">3949</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Try with different learning rates for each Optimizer (0.0001 and 0.001 ) and different Batch sizes (50 and 128) for 20000 Epochs.</p>
</li>
<li><p>For each optimizer, plot (on the same curve) the <strong>testing accuracies</strong> function to <strong>(learning rate, batch size)</strong></p>
</li>
</ul>
<ul>
<li>Did you reach the 99% accuracy ? What are the optimal parametres that gave you the best results? </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="alert alert-success">
We can see that the testing and validation accuracy are very low for the AdamOptimizer whereas it is high (more than 98% ) for SGD. 
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># The function Lenet5 with Relu</span>

<span class="kn">from</span> <span class="nn">tensorflow.contrib.layers</span> <span class="kn">import</span> <span class="n">flatten</span>


<span class="k">def</span> <span class="nf">LeNet5_Model</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>    
    <span class="c1"># your inmplementation goes here</span>
    <span class="c1">#Layer 1: Convolutional</span>
    <span class="n">layer1_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
    <span class="n">layer1_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">6</span><span class="p">,))</span>
    <span class="n">data2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="n">layer1_weights</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">layer1_bias</span>
    <span class="c1">#Activation. sigmoid</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv1</span><span class="p">)</span>
    <span class="c1">#Pooling</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">conv1</span> <span class="p">,</span><span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    
    
    <span class="c1">#Layer 2: Convolutional</span>
    <span class="n">layer2_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">16</span><span class="p">))</span>
    <span class="n">layer2_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">16</span><span class="p">,))</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="n">layer2_weights</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;VALID&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">layer2_bias</span>
    <span class="c1">#Activation. relu</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>
    <span class="c1">#Pooling</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">conv2</span> <span class="p">,</span><span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    
    <span class="c1">#Flatten</span>
    <span class="n">conv_flat</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>
    
    <span class="c1">#Layer 3: Fully Connected</span>
    <span class="n">layer3_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">400</span><span class="p">,</span> <span class="mi">120</span><span class="p">))</span>
    <span class="n">layer3_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">120</span><span class="p">,))</span>
    <span class="n">layer3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span><span class="n">conv_flat</span><span class="p">,</span><span class="n">layer3_weights</span><span class="p">,</span><span class="n">layer3_bias</span><span class="p">)</span>

    <span class="c1">#Activation. relu</span>
    
    <span class="n">layer3_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">layer3</span><span class="p">)</span>
    
    <span class="c1">#Layer 4: Fully Connected</span>
    <span class="n">layer4_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">))</span>
    <span class="n">layer4_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">84</span><span class="p">,))</span>
    <span class="n">layer4</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span> <span class="n">layer3_out</span><span class="p">,</span><span class="n">layer4_weights</span><span class="p">,</span><span class="n">layer4_bias</span><span class="p">)</span>

    <span class="c1">#Activation. relu</span>
    
    <span class="n">layer4_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">layer4</span><span class="p">)</span>
    
    <span class="c1">#Layer 5: Fully Connected</span>
    <span class="n">layer5_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">layer5_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">10</span><span class="p">,))</span>
    <span class="n">layer5</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span> <span class="n">layer4_out</span><span class="p">,</span><span class="n">layer5_weights</span><span class="p">,</span><span class="n">layer5_bias</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">layer5</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">layer5</span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>


<span class="c1"># Train with Relu and SGD</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># Gradient Descent</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train with SGD and lambda = 0.1     </span>
    
<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_Sgd&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;01&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.424927371&#39;)
(&#39;Accuracy: Training :&#39;, 0.95956363639831543)
(&#39;Accuracy: Validation :&#39;, 0.96179999999999999)
(&#39;Epoch: &#39;, &#39;02&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.102323309&#39;)
(&#39;Accuracy: Training :&#39;, 0.97492727272727275)
(&#39;Accuracy: Validation :&#39;, 0.97599999999999998)
(&#39;Epoch: &#39;, &#39;03&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.072147082&#39;)
(&#39;Accuracy: Training :&#39;, 0.97398181818181817)
(&#39;Accuracy: Validation :&#39;, 0.97319999999999995)
(&#39;Epoch: &#39;, &#39;04&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.055713680&#39;)
(&#39;Accuracy: Training :&#39;, 0.97987272727272723)
(&#39;Accuracy: Validation :&#39;, 0.97740000000000005)
(&#39;Epoch: &#39;, &#39;05&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.045901190&#39;)
(&#39;Accuracy: Training :&#39;, 0.98325454545454549)
(&#39;Accuracy: Validation :&#39;, 0.98080000000000001)
(&#39;Epoch: &#39;, &#39;06&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.038947267&#39;)
(&#39;Accuracy: Training :&#39;, 0.98549090909090908)
(&#39;Accuracy: Validation :&#39;, 0.98180000000000001)
(&#39;Epoch: &#39;, &#39;07&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.032691751&#39;)
(&#39;Accuracy: Training :&#39;, 0.98909090909090913)
(&#39;Accuracy: Validation :&#39;, 0.98440000000000005)
(&#39;Epoch: &#39;, &#39;08&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.029214070&#39;)
(&#39;Accuracy: Training :&#39;, 0.98967272727272726)
(&#39;Accuracy: Validation :&#39;, 0.98560000000000003)
(&#39;Epoch: &#39;, &#39;09&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.026541297&#39;)
(&#39;Accuracy: Training :&#39;, 0.99112727272727275)
(&#39;Accuracy: Validation :&#39;, 0.98719999999999997)
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.023463221&#39;)
(&#39;Accuracy: Training :&#39;, 0.99505454545454541)
(&#39;Accuracy: Validation :&#39;, 0.98819999999999997)
(&#39;Epoch: &#39;, &#39;11&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.019658876&#39;)
(&#39;Accuracy: Training :&#39;, 0.99423636363636358)
(&#39;Accuracy: Validation :&#39;, 0.98780000000000001)
(&#39;Epoch: &#39;, &#39;12&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.018796629&#39;)
(&#39;Accuracy: Training :&#39;, 0.9925090909090909)
(&#39;Accuracy: Validation :&#39;, 0.98299999999999998)
(&#39;Epoch: &#39;, &#39;13&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.016492111&#39;)
(&#39;Accuracy: Training :&#39;, 0.99290909090909096)
(&#39;Accuracy: Validation :&#39;, 0.98419999999999996)
(&#39;Epoch: &#39;, &#39;14&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.014760773&#39;)
(&#39;Accuracy: Training :&#39;, 0.99689090909090905)
(&#39;Accuracy: Validation :&#39;, 0.98599999999999999)
(&#39;Epoch: &#39;, &#39;15&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.012386306&#39;)
(&#39;Accuracy: Training :&#39;, 0.99667272727272727)
(&#39;Accuracy: Validation :&#39;, 0.98799999999999999)
(&#39;Epoch: &#39;, &#39;16&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.011450042&#39;)
(&#39;Accuracy: Training :&#39;, 0.99687272727272724)
(&#39;Accuracy: Validation :&#39;, 0.98780000000000001)
(&#39;Epoch: &#39;, &#39;17&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.010062471&#39;)
(&#39;Accuracy: Training :&#39;, 0.99783636363636363)
(&#39;Accuracy: Validation :&#39;, 0.98860000000000003)
(&#39;Epoch: &#39;, &#39;18&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.008579700&#39;)
(&#39;Accuracy: Training :&#39;, 0.99825454545454551)
(&#39;Accuracy: Validation :&#39;, 0.98839999999999995)
(&#39;Epoch: &#39;, &#39;19&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.008412874&#39;)
(&#39;Accuracy: Training :&#39;, 0.99781818181818183)
(&#39;Accuracy: Validation :&#39;, 0.98760000000000003)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.006742653&#39;)
(&#39;Accuracy: Training :&#39;, 0.9985090909090909)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;21&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.006492131&#39;)
(&#39;Accuracy: Training :&#39;, 0.99929090909090912)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;22&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.005261287&#39;)
(&#39;Accuracy: Training :&#39;, 0.99794545454545458)
(&#39;Accuracy: Validation :&#39;, 0.98860000000000003)
(&#39;Epoch: &#39;, &#39;23&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.004992700&#39;)
(&#39;Accuracy: Training :&#39;, 0.99925454545454551)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;24&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003633182&#39;)
(&#39;Accuracy: Training :&#39;, 0.99903636363636361)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;25&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003091187&#39;)
(&#39;Accuracy: Training :&#39;, 0.99938181818181815)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;26&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003996929&#39;)
(&#39;Accuracy: Training :&#39;, 0.99961818181818185)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;27&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.002304896&#39;)
(&#39;Accuracy: Training :&#39;, 0.99970909090909088)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;28&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.001809187&#39;)
(&#39;Accuracy: Training :&#39;, 0.99981818181818183)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;29&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.001438150&#39;)
(&#39;Accuracy: Training :&#39;, 0.99896363636363639)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.140732294&#39;)
(&#39;Accuracy: Training :&#39;, 0.98494545458013361)
(&#39;Accuracy: Validation :&#39;, 0.98140000000000005)
(&#39;Epoch: &#39;, &#39;31&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.035157994&#39;)
(&#39;Accuracy: Training :&#39;, 0.9918181818355214)
(&#39;Accuracy: Validation :&#39;, 0.98760000000000003)
(&#39;Epoch: &#39;, &#39;32&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.026670990&#39;)
(&#39;Accuracy: Training :&#39;, 0.99403636363636361)
(&#39;Accuracy: Validation :&#39;, 0.98740000000000006)
(&#39;Epoch: &#39;, &#39;33&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.020478641&#39;)
(&#39;Accuracy: Training :&#39;, 0.99305454545454541)
(&#39;Accuracy: Validation :&#39;, 0.98560000000000003)
(&#39;Epoch: &#39;, &#39;34&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.015500393&#39;)
(&#39;Accuracy: Training :&#39;, 0.99543636363636367)
(&#39;Accuracy: Validation :&#39;, 0.98680000000000001)
(&#39;Epoch: &#39;, &#39;35&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.013852639&#39;)
(&#39;Accuracy: Training :&#39;, 0.99536363636363634)
(&#39;Accuracy: Validation :&#39;, 0.98860000000000003)
(&#39;Epoch: &#39;, &#39;36&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.010992813&#39;)
(&#39;Accuracy: Training :&#39;, 0.99694545454545458)
(&#39;Accuracy: Validation :&#39;, 0.98699999999999999)
(&#39;Epoch: &#39;, &#39;37&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.008208168&#39;)
(&#39;Accuracy: Training :&#39;, 0.99898181818181819)
(&#39;Accuracy: Validation :&#39;, 0.98780000000000001)
(&#39;Epoch: &#39;, &#39;38&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.007122806&#39;)
(&#39;Accuracy: Training :&#39;, 0.99661818181818185)
(&#39;Accuracy: Validation :&#39;, 0.98660000000000003)
(&#39;Epoch: &#39;, &#39;39&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.005887663&#39;)
(&#39;Accuracy: Training :&#39;, 0.99919999999999998)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.004438830&#39;)
(&#39;Accuracy: Training :&#39;, 0.99830909090909092)
(&#39;Accuracy: Validation :&#39;, 0.98839999999999995)
(&#39;Epoch: &#39;, &#39;41&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003601862&#39;)
(&#39;Accuracy: Training :&#39;, 0.99909090909090914)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;42&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.002829276&#39;)
(&#39;Accuracy: Training :&#39;, 0.99894545454545458)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;43&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.002316276&#39;)
(&#39;Accuracy: Training :&#39;, 0.99925454545454551)
(&#39;Accuracy: Validation :&#39;, 0.98880000000000001)
(&#39;Epoch: &#39;, &#39;44&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.002880198&#39;)
(&#39;Accuracy: Training :&#39;, 0.99981818181818183)
(&#39;Accuracy: Validation :&#39;, 0.98919999999999997)
(&#39;Epoch: &#39;, &#39;45&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.001843907&#39;)
(&#39;Accuracy: Training :&#39;, 0.99981818181818183)
(&#39;Accuracy: Validation :&#39;, 0.99039999999999995)
(&#39;Epoch: &#39;, &#39;46&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.001026244&#39;)
(&#39;Accuracy: Training :&#39;, 0.99992727272727278)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;47&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.001044972&#39;)
(&#39;Accuracy: Training :&#39;, 0.99981818181818183)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;48&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.002072395&#39;)
(&#39;Accuracy: Training :&#39;, 0.99943636363636368)
(&#39;Accuracy: Validation :&#39;, 0.98899999999999999)
(&#39;Epoch: &#39;, &#39;49&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.001503998&#39;)
(&#39;Accuracy: Training :&#39;, 0.99989090909090905)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000677775&#39;)
(&#39;Accuracy: Training :&#39;, 0.99998181818181819)
(&#39;Accuracy: Validation :&#39;, 0.98919999999999997)
(&#39;Epoch: &#39;, &#39;51&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000470110&#39;)
(&#39;Accuracy: Training :&#39;, 0.99992727272727278)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;52&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000384917&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;53&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000331350&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;54&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000285736&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;55&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000252879&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;56&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000233856&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;57&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000217902&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;58&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000213566&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;59&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000195886&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000183986&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;61&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000172642&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99039999999999995)
(&#39;Epoch: &#39;, &#39;62&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000160193&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;63&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000152853&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;64&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000144727&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;65&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000141090&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;66&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000135249&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;67&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000126854&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;68&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000123775&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;69&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000118133&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000112212&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;71&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000109961&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;72&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000105069&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;73&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000101236&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;74&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000097360&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;75&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000094588&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99080000000000001)
(&#39;Epoch: &#39;, &#39;76&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000091452&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;77&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000089031&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99039999999999995)
(&#39;Epoch: &#39;, &#39;78&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000085672&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;79&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000083195&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000081607&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;81&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000077992&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;82&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000076440&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99039999999999995)
(&#39;Epoch: &#39;, &#39;83&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000073449&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99080000000000001)
(&#39;Epoch: &#39;, &#39;84&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000072107&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;85&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000070393&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;86&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000068946&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;87&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000067206&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;88&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000065589&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;89&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000063905&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99039999999999995)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000062938&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;91&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000061010&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99080000000000001)
(&#39;Epoch: &#39;, &#39;92&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000059474&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;93&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000058622&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;94&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000057261&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;95&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000055654&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;96&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000055288&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;97&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000053291&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99080000000000001)
(&#39;Epoch: &#39;, &#39;98&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000052781&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99039999999999995)
(&#39;Epoch: &#39;, &#39;99&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000051227&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000050439&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Accuracy: Test :&#39;, 0.98960000000000004)
Training Finished!
(&#39;Training time =&#39;, 3889.4031660556793)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Train with Relu and AdamOptimizer</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># AdamOptimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train with Relu and AdamOptimizer</span>

<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_adam&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;01&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.969809670&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818186153064)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;02&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313509241&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909091450952)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;03&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312286340&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454978943)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;04&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312508576&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818186153064)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;05&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313032494&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818181818185)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;06&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312933858&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545455412431)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;07&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313321259&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981818184527489)
(&#39;Accuracy: Validation :&#39;, 0.092399999999999996)
(&#39;Epoch: &#39;, &#39;08&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312830921&#39;)
(&#39;Accuracy: Training :&#39;, 0.09798181818832051)
(&#39;Accuracy: Validation :&#39;, 0.092399999999999996)
(&#39;Epoch: &#39;, &#39;09&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312553365&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454978943)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313353491&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163636370138683)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;11&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312365262&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454328711)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;12&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313259947&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909091180021)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;13&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312492552&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909090909091)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;14&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312881885&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454545459964058)
(&#39;Accuracy: Validation :&#39;, 0.097600000000000006)
(&#39;Epoch: &#39;, &#39;15&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313178501&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454978943)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;16&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311794189&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454545443708242)
(&#39;Accuracy: Validation :&#39;, 0.097600000000000006)
(&#39;Epoch: &#39;, &#39;17&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313162958&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909091450952)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;18&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312422370&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454545487057)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;19&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312911255&#39;)
(&#39;Accuracy: Training :&#39;, 0.09916363636363637)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312601422&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490909097411414)
(&#39;Accuracy: Validation :&#39;, 0.1002)
(&#39;Epoch: &#39;, &#39;21&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312566915&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909091450951)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;22&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313049162&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981818183985617)
(&#39;Accuracy: Validation :&#39;, 0.092399999999999996)
(&#39;Epoch: &#39;, &#39;23&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313320999&#39;)
(&#39;Accuracy: Training :&#39;, 0.09916363635279915)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;24&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312043758&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545455087315)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;25&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312884661&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454545461047775)
(&#39;Accuracy: Validation :&#39;, 0.097600000000000006)
(&#39;Epoch: &#39;, &#39;26&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313161987&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909091776068)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;27&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313229073&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454328711)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;28&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313479561&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981818180734467)
(&#39;Accuracy: Validation :&#39;, 0.092399999999999996)
(&#39;Epoch: &#39;, &#39;29&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313961437&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818187236781)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313772928&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545453461733)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;31&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313108506&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909091559324)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;32&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312672488&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909091559324)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;33&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312601665&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490909094160251)
(&#39;Accuracy: Validation :&#39;, 0.1002)
(&#39;Epoch: &#39;, &#39;34&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313058500&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163636369054967)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;35&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312775635&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490909095243979)
(&#39;Accuracy: Validation :&#39;, 0.107)
(&#39;Epoch: &#39;, &#39;36&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312655977&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545455195687)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;37&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312904521&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454545454545448)
(&#39;Accuracy: Validation :&#39;, 0.097600000000000006)
(&#39;Epoch: &#39;, &#39;38&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312585965&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454328711)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;39&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313453685&#39;)
(&#39;Accuracy: Training :&#39;, 0.1025090908982537)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312677926&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909090692346)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;41&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313352108&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909090909091)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;42&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313121282&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818173148411)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;43&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312514963&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163636361468924)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;44&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313513540&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909091180022)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;45&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312959305&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454545458880342)
(&#39;Accuracy: Validation :&#39;, 0.097600000000000006)
(&#39;Epoch: &#39;, &#39;46&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313920600&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981818179650737)
(&#39;Accuracy: Validation :&#39;, 0.092399999999999996)
(&#39;Epoch: &#39;, &#39;47&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312212049&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454545487057)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;48&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312766833&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454437082)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;49&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311762981&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490909086574208)
(&#39;Accuracy: Validation :&#39;, 0.1002)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313278478&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909091342579)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;51&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313280198&#39;)
(&#39;Accuracy: Training :&#39;, 0.1039090908982537)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;52&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312306343&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545455087315)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;53&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312441982&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909091450951)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;54&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312695951&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454545452378015)
(&#39;Accuracy: Validation :&#39;, 0.097600000000000006)
(&#39;Epoch: &#39;, &#39;55&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312558902&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454437082)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;56&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313062264&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490909093618392)
(&#39;Accuracy: Validation :&#39;, 0.1002)
(&#39;Epoch: &#39;, &#39;57&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312138789&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454816385)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;58&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312919110&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163636370138683)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;59&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313314020&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818187236781)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312997986&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454545454)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;61&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312612836&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818181818185)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;62&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312989941&#39;)
(&#39;Accuracy: Training :&#39;, 0.1039090908982537)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;63&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311992775&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909091559324)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;64&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312814911&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909090475603)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;65&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313164138&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490909080071879)
(&#39;Accuracy: Validation :&#39;, 0.107)
(&#39;Epoch: &#39;, &#39;66&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311746653&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490909092534676)
(&#39;Accuracy: Validation :&#39;, 0.1002)
(&#39;Epoch: &#39;, &#39;67&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312543795&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545453461733)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;68&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311696046&#39;)
(&#39;Accuracy: Training :&#39;, 0.09916363635279915)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;69&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313374786&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545453461733)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312594531&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454111966)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;71&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312680757&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545455195687)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;72&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312649590&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490909093618392)
(&#39;Accuracy: Validation :&#39;, 0.1002)
(&#39;Epoch: &#39;, &#39;73&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312881621&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909091450951)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;74&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313276935&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909091559324)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;75&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312925283&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545455087315)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;76&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312984661&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454437082)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;77&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313042789&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909091342579)
(&#39;Accuracy: Validation :&#39;, 0.11)
(&#39;Epoch: &#39;, &#39;78&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312594048&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818179650738)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;79&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312861103&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454762199)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312875450&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981818177483304)
(&#39;Accuracy: Validation :&#39;, 0.092399999999999996)
(&#39;Epoch: &#39;, &#39;81&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313165181&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818181818185)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;82&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312798900&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818188320511)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;83&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313128529&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545453461733)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;84&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313588210&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454545487057)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;85&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312892783&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981818177483304)
(&#39;Accuracy: Validation :&#39;, 0.092399999999999996)
(&#39;Epoch: &#39;, &#39;86&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313538389&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909091450951)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;87&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311880986&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818185069348)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;88&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312990016&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981818187236781)
(&#39;Accuracy: Validation :&#39;, 0.095799999999999996)
(&#39;Epoch: &#39;, &#39;89&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313207455&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909090909091)
(&#39;Accuracy: Validation :&#39;, 0.098599999999999993)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313184716&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490909097411412)
(&#39;Accuracy: Validation :&#39;, 0.107)
(&#39;Epoch: &#39;, &#39;91&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312803634&#39;)
(&#39;Accuracy: Training :&#39;, 0.09916363636255264)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;92&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313480005&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981818186153063)
(&#39;Accuracy: Validation :&#39;, 0.092399999999999996)
(&#39;Epoch: &#39;, &#39;93&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312989043&#39;)
(&#39;Accuracy: Training :&#39;, 0.09916363636255264)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;94&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311772079&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545455087315)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;95&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313877726&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454545453461732)
(&#39;Accuracy: Validation :&#39;, 0.097600000000000006)
(&#39;Epoch: &#39;, &#39;96&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312340825&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545455087315)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;97&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312823957&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454978943)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;98&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312828022&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545454978943)
(&#39;Accuracy: Validation :&#39;, 0.11260000000000001)
(&#39;Epoch: &#39;, &#39;99&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312054501&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163636361468924)
(&#39;Accuracy: Validation :&#39;, 0.099000000000000005)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.313888842&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981818185069347)
(&#39;Accuracy: Validation :&#39;, 0.092399999999999996)
Training Finished!
(&#39;Accuracy: Test :&#39;, 0.0974)
(&#39;Training time =&#39;, 3949.4650218486786)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># Gradient Descent</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train with learning rate = 0.001 and SGD   </span>
    
<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_sgd_0_001&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;01&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.308859379&#39;)
(&#39;Accuracy: Training :&#39;, 0.1299090908982537)
(&#39;Accuracy: Validation :&#39;, 0.125)
(&#39;Epoch: &#39;, &#39;02&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.272638228&#39;)
(&#39;Accuracy: Training :&#39;, 0.27821818180084229)
(&#39;Accuracy: Validation :&#39;, 0.26939999999999997)
(&#39;Epoch: &#39;, &#39;03&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.238331408&#39;)
(&#39;Accuracy: Training :&#39;, 0.43327272729440169)
(&#39;Accuracy: Validation :&#39;, 0.42720000000000002)
(&#39;Epoch: &#39;, &#39;04&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.181037711&#39;)
(&#39;Accuracy: Training :&#39;, 0.54601818184419115)
(&#39;Accuracy: Validation :&#39;, 0.5444)
(&#39;Epoch: &#39;, &#39;05&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.061269987&#39;)
(&#39;Accuracy: Training :&#39;, 0.6258181818615306)
(&#39;Accuracy: Validation :&#39;, 0.627)
(&#39;Epoch: &#39;, &#39;06&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.762059866&#39;)
(&#39;Accuracy: Training :&#39;, 0.68849090910824862)
(&#39;Accuracy: Validation :&#39;, 0.68440000000000001)
(&#39;Epoch: &#39;, &#39;07&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.200393937&#39;)
(&#39;Accuracy: Training :&#39;, 0.76709090909957889)
(&#39;Accuracy: Validation :&#39;, 0.76759999999999995)
(&#39;Epoch: &#39;, &#39;08&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.788267165&#39;)
(&#39;Accuracy: Training :&#39;, 0.80990909091776064)
(&#39;Accuracy: Validation :&#39;, 0.81499999999999995)
(&#39;Epoch: &#39;, &#39;09&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.606886074&#39;)
(&#39;Accuracy: Training :&#39;, 0.84147272722937849)
(&#39;Accuracy: Validation :&#39;, 0.8458)
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.510106773&#39;)
(&#39;Accuracy: Training :&#39;, 0.86370909087441183)
(&#39;Accuracy: Validation :&#39;, 0.86939999999999995)
(&#39;Epoch: &#39;, &#39;11&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.449577645&#39;)
(&#39;Accuracy: Training :&#39;, 0.87927272727272732)
(&#39;Accuracy: Validation :&#39;, 0.88280000000000003)
(&#39;Epoch: &#39;, &#39;12&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.407600117&#39;)
(&#39;Accuracy: Training :&#39;, 0.88780000000000003)
(&#39;Accuracy: Validation :&#39;, 0.89380000000000004)
(&#39;Epoch: &#39;, &#39;13&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.377457594&#39;)
(&#39;Accuracy: Training :&#39;, 0.89543636367104273)
(&#39;Accuracy: Validation :&#39;, 0.9022)
(&#39;Epoch: &#39;, &#39;14&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.353739286&#39;)
(&#39;Accuracy: Training :&#39;, 0.90129090905622999)
(&#39;Accuracy: Validation :&#39;, 0.90739999999999998)
(&#39;Epoch: &#39;, &#39;15&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.335189359&#39;)
(&#39;Accuracy: Training :&#39;, 0.90572727275328202)
(&#39;Accuracy: Validation :&#39;, 0.91100000000000003)
(&#39;Epoch: &#39;, &#39;16&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.319639402&#39;)
(&#39;Accuracy: Training :&#39;, 0.91018181814713917)
(&#39;Accuracy: Validation :&#39;, 0.91659999999999997)
(&#39;Epoch: &#39;, &#39;17&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.306404017&#39;)
(&#39;Accuracy: Training :&#39;, 0.91327272724671793)
(&#39;Accuracy: Validation :&#39;, 0.91859999999999997)
(&#39;Epoch: &#39;, &#39;18&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.294384323&#39;)
(&#39;Accuracy: Training :&#39;, 0.91656363632028748)
(&#39;Accuracy: Validation :&#39;, 0.92100000000000004)
(&#39;Epoch: &#39;, &#39;19&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.283918548&#39;)
(&#39;Accuracy: Training :&#39;, 0.91959999996532094)
(&#39;Accuracy: Validation :&#39;, 0.9254)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.274284871&#39;)
(&#39;Accuracy: Training :&#39;, 0.92292727277062159)
(&#39;Accuracy: Validation :&#39;, 0.92620000000000002)
(&#39;Epoch: &#39;, &#39;21&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.265241045&#39;)
(&#39;Accuracy: Training :&#39;, 0.92463636362769386)
(&#39;Accuracy: Validation :&#39;, 0.92620000000000002)
(&#39;Epoch: &#39;, &#39;22&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.256937661&#39;)
(&#39;Accuracy: Training :&#39;, 0.92676363640698523)
(&#39;Accuracy: Validation :&#39;, 0.9294)
(&#39;Epoch: &#39;, &#39;23&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.249388156&#39;)
(&#39;Accuracy: Training :&#39;, 0.92878181817314842)
(&#39;Accuracy: Validation :&#39;, 0.93140000000000001)
(&#39;Epoch: &#39;, &#39;24&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.242610054&#39;)
(&#39;Accuracy: Training :&#39;, 0.93040000000866974)
(&#39;Accuracy: Validation :&#39;, 0.93459999999999999)
(&#39;Epoch: &#39;, &#39;25&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.235979079&#39;)
(&#39;Accuracy: Training :&#39;, 0.93196363632895729)
(&#39;Accuracy: Validation :&#39;, 0.93799999999999994)
(&#39;Epoch: &#39;, &#39;26&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.229535631&#39;)
(&#39;Accuracy: Training :&#39;, 0.93394545453678479)
(&#39;Accuracy: Validation :&#39;, 0.93659999999999999)
(&#39;Epoch: &#39;, &#39;27&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.223602325&#39;)
(&#39;Accuracy: Training :&#39;, 0.9363454545714639)
(&#39;Accuracy: Validation :&#39;, 0.93999999999999995)
(&#39;Epoch: &#39;, &#39;28&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.217910342&#39;)
(&#39;Accuracy: Training :&#39;, 0.93738181817314836)
(&#39;Accuracy: Validation :&#39;, 0.94140000000000001)
(&#39;Epoch: &#39;, &#39;29&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.212314915&#39;)
(&#39;Accuracy: Training :&#39;, 0.93943636364503336)
(&#39;Accuracy: Validation :&#39;, 0.94320000000000004)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.207280244&#39;)
(&#39;Accuracy: Training :&#39;, 0.94098181817314841)
(&#39;Accuracy: Validation :&#39;, 0.94540000000000002)
(&#39;Epoch: &#39;, &#39;31&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.202463566&#39;)
(&#39;Accuracy: Training :&#39;, 0.94218181814713908)
(&#39;Accuracy: Validation :&#39;, 0.94699999999999995)
(&#39;Epoch: &#39;, &#39;32&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.197588805&#39;)
(&#39;Accuracy: Training :&#39;, 0.94350909090042112)
(&#39;Accuracy: Validation :&#39;, 0.9476)
(&#39;Epoch: &#39;, &#39;33&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.193204739&#39;)
(&#39;Accuracy: Training :&#39;, 0.9443636363376271)
(&#39;Accuracy: Validation :&#39;, 0.9486)
(&#39;Epoch: &#39;, &#39;34&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.188824084&#39;)
(&#39;Accuracy: Training :&#39;, 0.94599999999133022)
(&#39;Accuracy: Validation :&#39;, 0.94999999999999996)
(&#39;Epoch: &#39;, &#39;35&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.184708496&#39;)
(&#39;Accuracy: Training :&#39;, 0.94667272729873653)
(&#39;Accuracy: Validation :&#39;, 0.95079999999999998)
(&#39;Epoch: &#39;, &#39;36&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.181074143&#39;)
(&#39;Accuracy: Training :&#39;, 0.94816363633762701)
(&#39;Accuracy: Validation :&#39;, 0.95079999999999998)
(&#39;Epoch: &#39;, &#39;37&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.177207801&#39;)
(&#39;Accuracy: Training :&#39;, 0.94876363638097594)
(&#39;Accuracy: Validation :&#39;, 0.95299999999999996)
(&#39;Epoch: &#39;, &#39;38&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.173702841&#39;)
(&#39;Accuracy: Training :&#39;, 0.95016363639831547)
(&#39;Accuracy: Validation :&#39;, 0.95440000000000003)
(&#39;Epoch: &#39;, &#39;39&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.170162248&#39;)
(&#39;Accuracy: Training :&#39;, 0.95083636362769386)
(&#39;Accuracy: Validation :&#39;, 0.95320000000000005)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.166686083&#39;)
(&#39;Accuracy: Training :&#39;, 0.95230909086574211)
(&#39;Accuracy: Validation :&#39;, 0.9556)
(&#39;Epoch: &#39;, &#39;41&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.163989767&#39;)
(&#39;Accuracy: Training :&#39;, 0.95321818185286089)
(&#39;Accuracy: Validation :&#39;, 0.95640000000000003)
(&#39;Epoch: &#39;, &#39;42&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.160673567&#39;)
(&#39;Accuracy: Training :&#39;, 0.95347272728139709)
(&#39;Accuracy: Validation :&#39;, 0.95720000000000005)
(&#39;Epoch: &#39;, &#39;43&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.157937170&#39;)
(&#39;Accuracy: Training :&#39;, 0.95399999996532092)
(&#39;Accuracy: Validation :&#39;, 0.95699999999999996)
(&#39;Epoch: &#39;, &#39;44&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.154933099&#39;)
(&#39;Accuracy: Training :&#39;, 0.95445454548922448)
(&#39;Accuracy: Validation :&#39;, 0.95699999999999996)
(&#39;Epoch: &#39;, &#39;45&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.151953646&#39;)
(&#39;Accuracy: Training :&#39;, 0.95636363638097588)
(&#39;Accuracy: Validation :&#39;, 0.95899999999999996)
(&#39;Epoch: &#39;, &#39;46&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.149704102&#39;)
(&#39;Accuracy: Training :&#39;, 0.95676363635496664)
(&#39;Accuracy: Validation :&#39;, 0.95979999999999999)
(&#39;Epoch: &#39;, &#39;47&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.147015315&#39;)
(&#39;Accuracy: Training :&#39;, 0.95599999995665119)
(&#39;Accuracy: Validation :&#39;, 0.95999999999999996)
(&#39;Epoch: &#39;, &#39;48&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.144730078&#39;)
(&#39;Accuracy: Training :&#39;, 0.9582181818528609)
(&#39;Accuracy: Validation :&#39;, 0.96099999999999997)
(&#39;Epoch: &#39;, &#39;49&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.142204318&#39;)
(&#39;Accuracy: Training :&#39;, 0.95883636365370317)
(&#39;Accuracy: Validation :&#39;, 0.96199999999999997)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.140083308&#39;)
(&#39;Accuracy: Training :&#39;, 0.95914545451944522)
(&#39;Accuracy: Validation :&#39;, 0.96199999999999997)
(&#39;Epoch: &#39;, &#39;51&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.138191608&#39;)
(&#39;Accuracy: Training :&#39;, 0.95963636359301485)
(&#39;Accuracy: Validation :&#39;, 0.96140000000000003)
(&#39;Epoch: &#39;, &#39;52&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.136026463&#39;)
(&#39;Accuracy: Training :&#39;, 0.96043636361035434)
(&#39;Accuracy: Validation :&#39;, 0.96440000000000003)
(&#39;Epoch: &#39;, &#39;53&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.133867474&#39;)
(&#39;Accuracy: Training :&#39;, 0.96130909088308159)
(&#39;Accuracy: Validation :&#39;, 0.96399999999999997)
(&#39;Epoch: &#39;, &#39;54&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.131929773&#39;)
(&#39;Accuracy: Training :&#39;, 0.96121818177483298)
(&#39;Accuracy: Validation :&#39;, 0.96360000000000001)
(&#39;Epoch: &#39;, &#39;55&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.130084594&#39;)
(&#39;Accuracy: Training :&#39;, 0.96170909094377)
(&#39;Accuracy: Validation :&#39;, 0.96299999999999997)
(&#39;Epoch: &#39;, &#39;56&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.128338136&#39;)
(&#39;Accuracy: Training :&#39;, 0.96210909091776065)
(&#39;Accuracy: Validation :&#39;, 0.96419999999999995)
(&#39;Epoch: &#39;, &#39;57&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.126369841&#39;)
(&#39;Accuracy: Training :&#39;, 0.9619818182164972)
(&#39;Accuracy: Validation :&#39;, 0.96460000000000001)
(&#39;Epoch: &#39;, &#39;58&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.124680908&#39;)
(&#39;Accuracy: Training :&#39;, 0.96367272722937847)
(&#39;Accuracy: Validation :&#39;, 0.96540000000000004)
(&#39;Epoch: &#39;, &#39;59&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.123012163&#39;)
(&#39;Accuracy: Training :&#39;, 0.96425454544587563)
(&#39;Accuracy: Validation :&#39;, 0.96519999999999995)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.121599754&#39;)
(&#39;Accuracy: Training :&#39;, 0.96489090906489983)
(&#39;Accuracy: Validation :&#39;, 0.96560000000000001)
(&#39;Epoch: &#39;, &#39;61&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.120201247&#39;)
(&#39;Accuracy: Training :&#39;, 0.96501818179217247)
(&#39;Accuracy: Validation :&#39;, 0.96640000000000004)
(&#39;Epoch: &#39;, &#39;62&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.118560978&#39;)
(&#39;Accuracy: Training :&#39;, 0.96463636359301486)
(&#39;Accuracy: Validation :&#39;, 0.96860000000000002)
(&#39;Epoch: &#39;, &#39;63&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.117108620&#39;)
(&#39;Accuracy: Training :&#39;, 0.96605454541119662)
(&#39;Accuracy: Validation :&#39;, 0.96779999999999999)
(&#39;Epoch: &#39;, &#39;64&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.115652039&#39;)
(&#39;Accuracy: Training :&#39;, 0.96652727276195183)
(&#39;Accuracy: Validation :&#39;, 0.96819999999999995)
(&#39;Epoch: &#39;, &#39;65&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.114460566&#39;)
(&#39;Accuracy: Training :&#39;, 0.96623636367104271)
(&#39;Accuracy: Validation :&#39;, 0.96740000000000004)
(&#39;Epoch: &#39;, &#39;66&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.112935593&#39;)
(&#39;Accuracy: Training :&#39;, 0.96654545451944529)
(&#39;Accuracy: Validation :&#39;, 0.96799999999999997)
(&#39;Epoch: &#39;, &#39;67&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.111544803&#39;)
(&#39;Accuracy: Training :&#39;, 0.96741818183552131)
(&#39;Accuracy: Validation :&#39;, 0.96799999999999997)
(&#39;Epoch: &#39;, &#39;68&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.110335369&#39;)
(&#39;Accuracy: Training :&#39;, 0.9676181818355214)
(&#39;Accuracy: Validation :&#39;, 0.96999999999999997)
(&#39;Epoch: &#39;, &#39;69&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.109209380&#39;)
(&#39;Accuracy: Training :&#39;, 0.96767272724671793)
(&#39;Accuracy: Validation :&#39;, 0.97060000000000002)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.107953465&#39;)
(&#39;Accuracy: Training :&#39;, 0.96832727276195174)
(&#39;Accuracy: Validation :&#39;, 0.9698)
(&#39;Epoch: &#39;, &#39;71&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.106834021&#39;)
(&#39;Accuracy: Training :&#39;, 0.96832727268392393)
(&#39;Accuracy: Validation :&#39;, 0.9708)
(&#39;Epoch: &#39;, &#39;72&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.105911592&#39;)
(&#39;Accuracy: Training :&#39;, 0.9693272727012634)
(&#39;Accuracy: Validation :&#39;, 0.97119999999999995)
(&#39;Epoch: &#39;, &#39;73&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.104739998&#39;)
(&#39;Accuracy: Training :&#39;, 0.96909090904756023)
(&#39;Accuracy: Validation :&#39;, 0.97119999999999995)
(&#39;Epoch: &#39;, &#39;74&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.103811487&#39;)
(&#39;Accuracy: Training :&#39;, 0.96863636359301475)
(&#39;Accuracy: Validation :&#39;, 0.97099999999999997)
(&#39;Epoch: &#39;, &#39;75&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.102711638&#39;)
(&#39;Accuracy: Training :&#39;, 0.96905454541119662)
(&#39;Accuracy: Validation :&#39;, 0.97099999999999997)
(&#39;Epoch: &#39;, &#39;76&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.101565068&#39;)
(&#39;Accuracy: Training :&#39;, 0.96989090904756026)
(&#39;Accuracy: Validation :&#39;, 0.97060000000000002)
(&#39;Epoch: &#39;, &#39;77&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.100725863&#39;)
(&#39;Accuracy: Training :&#39;, 0.97023636359301479)
(&#39;Accuracy: Validation :&#39;, 0.97040000000000004)
(&#39;Epoch: &#39;, &#39;78&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.099857261&#39;)
(&#39;Accuracy: Training :&#39;, 0.97049090912558811)
(&#39;Accuracy: Validation :&#39;, 0.97160000000000002)
(&#39;Epoch: &#39;, &#39;79&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.098733956&#39;)
(&#39;Accuracy: Training :&#39;, 0.97056363638097587)
(&#39;Accuracy: Validation :&#39;, 0.9718)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.097882374&#39;)
(&#39;Accuracy: Training :&#39;, 0.97096363638097594)
(&#39;Accuracy: Validation :&#39;, 0.97099999999999997)
(&#39;Epoch: &#39;, &#39;81&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.097280584&#39;)
(&#39;Accuracy: Training :&#39;, 0.97110909088308162)
(&#39;Accuracy: Validation :&#39;, 0.97199999999999998)
(&#39;Epoch: &#39;, &#39;82&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.095937504&#39;)
(&#39;Accuracy: Training :&#39;, 0.97169090904756028)
(&#39;Accuracy: Validation :&#39;, 0.9728)
(&#39;Epoch: &#39;, &#39;83&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.095538593&#39;)
(&#39;Accuracy: Training :&#39;, 0.97110909086574204)
(&#39;Accuracy: Validation :&#39;, 0.9728)
(&#39;Epoch: &#39;, &#39;84&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.094479875&#39;)
(&#39;Accuracy: Training :&#39;, 0.97183636359301484)
(&#39;Accuracy: Validation :&#39;, 0.97219999999999995)
(&#39;Epoch: &#39;, &#39;85&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.093826514&#39;)
(&#39;Accuracy: Training :&#39;, 0.9728181818181818)
(&#39;Accuracy: Validation :&#39;, 0.9728)
(&#39;Epoch: &#39;, &#39;86&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.092881510&#39;)
(&#39;Accuracy: Training :&#39;, 0.97260000000000002)
(&#39;Accuracy: Validation :&#39;, 0.97399999999999998)
(&#39;Epoch: &#39;, &#39;87&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.092351882&#39;)
(&#39;Accuracy: Training :&#39;, 0.97247272727272727)
(&#39;Accuracy: Validation :&#39;, 0.97360000000000002)
(&#39;Epoch: &#39;, &#39;88&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.091449788&#39;)
(&#39;Accuracy: Training :&#39;, 0.97303636362769386)
(&#39;Accuracy: Validation :&#39;, 0.9728)
(&#39;Epoch: &#39;, &#39;89&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.090987916&#39;)
(&#39;Accuracy: Training :&#39;, 0.97309090906489981)
(&#39;Accuracy: Validation :&#39;, 0.9728)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.090163395&#39;)
(&#39;Accuracy: Training :&#39;, 0.97320000001733953)
(&#39;Accuracy: Validation :&#39;, 0.97340000000000004)
(&#39;Epoch: &#39;, &#39;91&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.089344147&#39;)
(&#39;Accuracy: Training :&#39;, 0.97229090910824867)
(&#39;Accuracy: Validation :&#39;, 0.97419999999999995)
(&#39;Epoch: &#39;, &#39;92&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.088670502&#39;)
(&#39;Accuracy: Training :&#39;, 0.97378181818181819)
(&#39;Accuracy: Validation :&#39;, 0.97519999999999996)
(&#39;Epoch: &#39;, &#39;93&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.087984434&#39;)
(&#39;Accuracy: Training :&#39;, 0.97390909090909095)
(&#39;Accuracy: Validation :&#39;, 0.97440000000000004)
(&#39;Epoch: &#39;, &#39;94&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.087590362&#39;)
(&#39;Accuracy: Training :&#39;, 0.97429090906489979)
(&#39;Accuracy: Validation :&#39;, 0.97440000000000004)
(&#39;Epoch: &#39;, &#39;95&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.086756915&#39;)
(&#39;Accuracy: Training :&#39;, 0.97340000003467908)
(&#39;Accuracy: Validation :&#39;, 0.97440000000000004)
(&#39;Epoch: &#39;, &#39;96&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.086199086&#39;)
(&#39;Accuracy: Training :&#39;, 0.97463636365370321)
(&#39;Accuracy: Validation :&#39;, 0.97540000000000004)
(&#39;Epoch: &#39;, &#39;97&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.085503662&#39;)
(&#39;Accuracy: Training :&#39;, 0.97440000003467908)
(&#39;Accuracy: Validation :&#39;, 0.97460000000000002)
(&#39;Epoch: &#39;, &#39;98&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.085149274&#39;)
(&#39;Accuracy: Training :&#39;, 0.97467272729006682)
(&#39;Accuracy: Validation :&#39;, 0.97560000000000002)
(&#39;Epoch: &#39;, &#39;99&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.084343526&#39;)
(&#39;Accuracy: Training :&#39;, 0.97541818179217255)
(&#39;Accuracy: Validation :&#39;, 0.97599999999999998)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.083618294&#39;)
(&#39;Accuracy: Training :&#39;, 0.97547272727272727)
(&#39;Accuracy: Validation :&#39;, 0.97519999999999996)
Training Finished!
(&#39;Accuracy: Test :&#39;, 0.97650000000000003)
(&#39;Training time =&#39;, 3913.0511100292206)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># Gradient Descent</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train with SGD and learning rate = 0.0001    </span>
    
<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_sgd_0_0001&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.258045942&#39;)
(&#39;Accuracy: Training :&#39;, 0.15903636363527993)
(&#39;Accuracy: Validation :&#39;, 0.16880000000000001)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.182504845&#39;)
(&#39;Accuracy: Training :&#39;, 0.41285454545454547)
(&#39;Accuracy: Validation :&#39;, 0.42680000000000001)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.016416979&#39;)
(&#39;Accuracy: Training :&#39;, 0.53987272723804824)
(&#39;Accuracy: Validation :&#39;, 0.54379999999999995)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.605511838&#39;)
(&#39;Accuracy: Training :&#39;, 0.63447272728139703)
(&#39;Accuracy: Validation :&#39;, 0.64480000000000004)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.044285088&#39;)
(&#39;Accuracy: Training :&#39;, 0.72405454546321524)
(&#39;Accuracy: Validation :&#39;, 0.7298)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.736914937&#39;)
(&#39;Accuracy: Training :&#39;, 0.78627272729006681)
(&#39;Accuracy: Validation :&#39;, 0.78859999999999997)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.593818298&#39;)
(&#39;Accuracy: Training :&#39;, 0.82379999999133025)
(&#39;Accuracy: Validation :&#39;, 0.82540000000000002)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.511189750&#39;)
(&#39;Accuracy: Training :&#39;, 0.84920000002600926)
(&#39;Accuracy: Validation :&#39;, 0.85319999999999996)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.456484565&#39;)
(&#39;Accuracy: Training :&#39;, 0.86490909086574208)
(&#39;Accuracy: Validation :&#39;, 0.87080000000000002)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.417979106&#39;)
(&#39;Accuracy: Training :&#39;, 0.8772545454285362)
(&#39;Accuracy: Validation :&#39;, 0.88400000000000001)
Training Finished!
(&#39;Accuracy: Test :&#39;, 0.88300000000000001)
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_text output_error">
<pre>

<span class="ansi-red-fg">NameError</span>Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-8-6d7f57e1f512&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-red-fg"># train</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> 
<span class="ansi-green-fg">----&gt; 6</span><span class="ansi-red-fg"> </span>train<span class="ansi-blue-fg">(</span>X_train<span class="ansi-blue-fg">,</span>y_train<span class="ansi-blue-fg">,</span>X_validation<span class="ansi-blue-fg">,</span>y_validation<span class="ansi-blue-fg">,</span>X_test<span class="ansi-blue-fg">,</span>y_test<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">&#34;lenet5_relu_sgd_0_0001&#34;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-5-4d975fd7b337&gt;</span> in <span class="ansi-cyan-fg">train</span><span class="ansi-blue-fg">(X_train, y_train, X_validation, y_validation, X_test, y_test, file_save)</span>
<span class="ansi-green-intense-fg ansi-bold">     54</span>             saver<span class="ansi-blue-fg">.</span>save<span class="ansi-blue-fg">(</span>sess<span class="ansi-blue-fg">,</span> file_save<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     55</span>             <span class="ansi-green-fg">print</span><span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Accuracy: Test :&#34;</span><span class="ansi-blue-fg">,</span> evaluate<span class="ansi-blue-fg">(</span>X_test<span class="ansi-blue-fg">,</span>y_test<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 56</span><span class="ansi-red-fg">         </span>training_time <span class="ansi-blue-fg">=</span> time<span class="ansi-blue-fg">.</span>time<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-</span> t0
<span class="ansi-green-intense-fg ansi-bold">     57</span>         <span class="ansi-green-fg">print</span><span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;Training time =&#39;</span><span class="ansi-blue-fg">,</span>training_time<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NameError</span>: global name &#39;t0&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># Gradient Descent</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train     </span>
    
<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_sgd_0_01_50&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;01&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.210098154&#39;)
(&#39;Accuracy: Training :&#39;, 0.53401818232102827)
(&#39;Accuracy: Validation :&#39;, 0.539600003361702)
(&#39;Epoch: &#39;, &#39;02&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.568450585&#39;)
(&#39;Accuracy: Training :&#39;, 0.77150908844037491)
(&#39;Accuracy: Validation :&#39;, 0.77219999670982364)
(&#39;Epoch: &#39;, &#39;03&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.676939681&#39;)
(&#39;Accuracy: Training :&#39;, 0.8461636310815811)
(&#39;Accuracy: Validation :&#39;, 0.84839999616146089)
(&#39;Epoch: &#39;, &#39;04&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.461702685&#39;)
(&#39;Accuracy: Training :&#39;, 0.8811090858416124)
(&#39;Accuracy: Validation :&#39;, 0.88499999463558199)
(&#39;Epoch: &#39;, &#39;05&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.379298006&#39;)
(&#39;Accuracy: Training :&#39;, 0.89747272355989971)
(&#39;Accuracy: Validation :&#39;, 0.90499999761581418)
(&#39;Epoch: &#39;, &#39;06&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.330032206&#39;)
(&#39;Accuracy: Training :&#39;, 0.91019999704577703)
(&#39;Accuracy: Validation :&#39;, 0.91559999823570248)
(&#39;Epoch: &#39;, &#39;07&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.296131350&#39;)
(&#39;Accuracy: Training :&#39;, 0.91729090636426758)
(&#39;Accuracy: Validation :&#39;, 0.92239999771118164)
(&#39;Epoch: &#39;, &#39;08&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.270243018&#39;)
(&#39;Accuracy: Training :&#39;, 0.92499999739907002)
(&#39;Accuracy: Validation :&#39;, 0.92979999601840968)
(&#39;Epoch: &#39;, &#39;09&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.249603844&#39;)
(&#39;Accuracy: Training :&#39;, 0.93038181570443235)
(&#39;Accuracy: Validation :&#39;, 0.93439999580383304)
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.232495265&#39;)
(&#39;Accuracy: Training :&#39;, 0.9337454518946734)
(&#39;Accuracy: Validation :&#39;, 0.93879999756813048)
(&#39;Epoch: &#39;, &#39;11&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.218276740&#39;)
(&#39;Accuracy: Training :&#39;, 0.93807272515513684)
(&#39;Accuracy: Validation :&#39;, 0.93979999959468841)
(&#39;Epoch: &#39;, &#39;12&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.204769902&#39;)
(&#39;Accuracy: Training :&#39;, 0.94229090766473245)
(&#39;Accuracy: Validation :&#39;, 0.9475999981164932)
(&#39;Epoch: &#39;, &#39;13&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.194113731&#39;)
(&#39;Accuracy: Training :&#39;, 0.94605454347350382)
(&#39;Accuracy: Validation :&#39;, 0.94799999892711639)
(&#39;Epoch: &#39;, &#39;14&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.184105906&#39;)
(&#39;Accuracy: Training :&#39;, 0.94825454343448989)
(&#39;Accuracy: Validation :&#39;, 0.94999999880790709)
(&#39;Epoch: &#39;, &#39;15&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.175827385&#39;)
(&#39;Accuracy: Training :&#39;, 0.95087272557345304)
(&#39;Accuracy: Validation :&#39;, 0.95299999833106996)
(&#39;Epoch: &#39;, &#39;16&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.167719308&#39;)
(&#39;Accuracy: Training :&#39;, 0.9528909079595046)
(&#39;Accuracy: Validation :&#39;, 0.95479999899864199)
(&#39;Epoch: &#39;, &#39;17&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.160986945&#39;)
(&#39;Accuracy: Training :&#39;, 0.95394545343789183)
(&#39;Accuracy: Validation :&#39;, 0.95539999783039098)
(&#39;Epoch: &#39;, &#39;18&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.154272424&#39;)
(&#39;Accuracy: Training :&#39;, 0.9563818176768043)
(&#39;Accuracy: Validation :&#39;, 0.95900000274181363)
(&#39;Epoch: &#39;, &#39;19&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.148647047&#39;)
(&#39;Accuracy: Training :&#39;, 0.95685454379428514)
(&#39;Accuracy: Validation :&#39;, 0.95739999651908869)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.143212385&#39;)
(&#39;Accuracy: Training :&#39;, 0.95889090841466729)
(&#39;Accuracy: Validation :&#39;, 0.96220000147819518)
(&#39;Epoch: &#39;, &#39;21&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.138527038&#39;)
(&#39;Accuracy: Training :&#39;, 0.96049090883948585)
(&#39;Accuracy: Validation :&#39;, 0.96259999930858609)
(&#39;Epoch: &#39;, &#39;22&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.134043604&#39;)
(&#39;Accuracy: Training :&#39;, 0.95896363572640853)
(&#39;Accuracy: Validation :&#39;, 0.96040000081062316)
(&#39;Epoch: &#39;, &#39;23&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.130365209&#39;)
(&#39;Accuracy: Training :&#39;, 0.96212727216157046)
(&#39;Accuracy: Validation :&#39;, 0.96360000014305114)
(&#39;Epoch: &#39;, &#39;24&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.126612527&#39;)
(&#39;Accuracy: Training :&#39;, 0.9625999992544001)
(&#39;Accuracy: Validation :&#39;, 0.96459999978542332)
(&#39;Epoch: &#39;, &#39;25&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.123236525&#39;)
(&#39;Accuracy: Training :&#39;, 0.96187272619117392)
(&#39;Accuracy: Validation :&#39;, 0.9623999965190887)
(&#39;Epoch: &#39;, &#39;26&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.119683540&#39;)
(&#39;Accuracy: Training :&#39;, 0.96598181843757625)
(&#39;Accuracy: Validation :&#39;, 0.96780000388622289)
(&#39;Epoch: &#39;, &#39;27&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.117006267&#39;)
(&#39;Accuracy: Training :&#39;, 0.96638181762261821)
(&#39;Accuracy: Validation :&#39;, 0.96940000116825109)
(&#39;Epoch: &#39;, &#39;28&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.114569058&#39;)
(&#39;Accuracy: Training :&#39;, 0.96647272787310856)
(&#39;Accuracy: Validation :&#39;, 0.96960000336170193)
(&#39;Epoch: &#39;, &#39;29&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.111656269&#39;)
(&#39;Accuracy: Training :&#39;, 0.96778181840072974)
(&#39;Accuracy: Validation :&#39;, 0.96940000236034396)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.108838668&#39;)
(&#39;Accuracy: Training :&#39;, 0.9668363639441403)
(&#39;Accuracy: Validation :&#39;, 0.96920000255107874)
(&#39;Epoch: &#39;, &#39;31&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.106922302&#39;)
(&#39;Accuracy: Training :&#39;, 0.96761818392710253)
(&#39;Accuracy: Validation :&#39;, 0.97120000481605528)
(&#39;Epoch: &#39;, &#39;32&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.104650922&#39;)
(&#39;Accuracy: Training :&#39;, 0.96981818275018172)
(&#39;Accuracy: Validation :&#39;, 0.97180000245571141)
(&#39;Epoch: &#39;, &#39;33&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.102460796&#39;)
(&#39;Accuracy: Training :&#39;, 0.97001818272200502)
(&#39;Accuracy: Validation :&#39;, 0.97100000262260433)
(&#39;Epoch: &#39;, &#39;34&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.100801109&#39;)
(&#39;Accuracy: Training :&#39;, 0.97020000067624179)
(&#39;Accuracy: Validation :&#39;, 0.97120000123977657)
(&#39;Epoch: &#39;, &#39;35&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.098600037&#39;)
(&#39;Accuracy: Training :&#39;, 0.97056363756006414)
(&#39;Accuracy: Validation :&#39;, 0.97320000171661381)
(&#39;Epoch: &#39;, &#39;36&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.096954359&#39;)
(&#39;Accuracy: Training :&#39;, 0.97043636517091236)
(&#39;Accuracy: Validation :&#39;, 0.97080000221729279)
(&#39;Epoch: &#39;, &#39;37&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.095041475&#39;)
(&#39;Accuracy: Training :&#39;, 0.97218182027339939)
(&#39;Accuracy: Validation :&#39;, 0.97460000216960907)
(&#39;Epoch: &#39;, &#39;38&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.093520891&#39;)
(&#39;Accuracy: Training :&#39;, 0.97260000136765568)
(&#39;Accuracy: Validation :&#39;, 0.97420000195503231)
(&#39;Epoch: &#39;, &#39;39&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.091802505&#39;)
(&#39;Accuracy: Training :&#39;, 0.97220000126145101)
(&#39;Accuracy: Validation :&#39;, 0.97360000312328343)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.090117033&#39;)
(&#39;Accuracy: Training :&#39;, 0.97261818278919565)
(&#39;Accuracy: Validation :&#39;, 0.97300000309944157)
(&#39;Epoch: &#39;, &#39;41&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.088882706&#39;)
(&#39;Accuracy: Training :&#39;, 0.97307272846048531)
(&#39;Accuracy: Validation :&#39;, 0.97360000193119045)
(&#39;Epoch: &#39;, &#39;42&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.087165264&#39;)
(&#39;Accuracy: Training :&#39;, 0.97403636574745178)
(&#39;Accuracy: Validation :&#39;, 0.97360000073909758)
(&#39;Epoch: &#39;, &#39;43&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.085880135&#39;)
(&#39;Accuracy: Training :&#39;, 0.97336363879117094)
(&#39;Accuracy: Validation :&#39;, 0.97320000112056737)
(&#39;Epoch: &#39;, &#39;44&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.084683572&#39;)
(&#39;Accuracy: Training :&#39;, 0.97480000235817654)
(&#39;Accuracy: Validation :&#39;, 0.97560000240802769)
(&#39;Epoch: &#39;, &#39;45&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.083400735&#39;)
(&#39;Accuracy: Training :&#39;, 0.97572727485136557)
(&#39;Accuracy: Validation :&#39;, 0.97559999883174897)
(&#39;Epoch: &#39;, &#39;46&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.081970342&#39;)
(&#39;Accuracy: Training :&#39;, 0.97445454765449868)
(&#39;Accuracy: Validation :&#39;, 0.97620000123977657)
(&#39;Epoch: &#39;, &#39;47&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.080710828&#39;)
(&#39;Accuracy: Training :&#39;, 0.97532727501609107)
(&#39;Accuracy: Validation :&#39;, 0.97340000152587891)
(&#39;Epoch: &#39;, &#39;48&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.079867145&#39;)
(&#39;Accuracy: Training :&#39;, 0.97580000243403697)
(&#39;Accuracy: Validation :&#39;, 0.97540000259876247)
(&#39;Epoch: &#39;, &#39;49&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.078697012&#39;)
(&#39;Accuracy: Training :&#39;, 0.97705454815517767)
(&#39;Accuracy: Validation :&#39;, 0.97580000221729279)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.077541373&#39;)
(&#39;Accuracy: Training :&#39;, 0.97527272993868053)
(&#39;Accuracy: Validation :&#39;, 0.97400000214576721)
(&#39;Epoch: &#39;, &#39;51&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.076237787&#39;)
(&#39;Accuracy: Training :&#39;, 0.97721818365833979)
(&#39;Accuracy: Validation :&#39;, 0.97600000083446503)
(&#39;Epoch: &#39;, &#39;52&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.075610040&#39;)
(&#39;Accuracy: Training :&#39;, 0.97643636589700522)
(&#39;Accuracy: Validation :&#39;, 0.97480000257492061)
(&#39;Epoch: &#39;, &#39;53&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.074453147&#39;)
(&#39;Accuracy: Training :&#39;, 0.97738182057033884)
(&#39;Accuracy: Validation :&#39;, 0.97480000197887418)
(&#39;Epoch: &#39;, &#39;54&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.073390900&#39;)
(&#39;Accuracy: Training :&#39;, 0.97841818403113967)
(&#39;Accuracy: Validation :&#39;, 0.97740000188350673)
(&#39;Epoch: &#39;, &#39;55&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.072690811&#39;)
(&#39;Accuracy: Training :&#39;, 0.97852727543223983)
(&#39;Accuracy: Validation :&#39;, 0.97740000367164614)
(&#39;Epoch: &#39;, &#39;56&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.072140557&#39;)
(&#39;Accuracy: Training :&#39;, 0.97778182029724126)
(&#39;Accuracy: Validation :&#39;, 0.97580000281333923)
(&#39;Epoch: &#39;, &#39;57&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.070906856&#39;)
(&#39;Accuracy: Training :&#39;, 0.97800000266595322)
(&#39;Accuracy: Validation :&#39;, 0.9774000012874603)
(&#39;Epoch: &#39;, &#39;58&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.070138956&#39;)
(&#39;Accuracy: Training :&#39;, 0.97881818457083269)
(&#39;Accuracy: Validation :&#39;, 0.97620000183582301)
(&#39;Epoch: &#39;, &#39;59&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.069274562&#39;)
(&#39;Accuracy: Training :&#39;, 0.97847272986715494)
(&#39;Accuracy: Validation :&#39;, 0.97720000386238093)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.068373921&#39;)
(&#39;Accuracy: Training :&#39;, 0.9788181835412979)
(&#39;Accuracy: Validation :&#39;, 0.97680000364780428)
(&#39;Epoch: &#39;, &#39;61&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.067953173&#39;)
(&#39;Accuracy: Training :&#39;, 0.97956364008513364)
(&#39;Accuracy: Validation :&#39;, 0.97600000381469731)
(&#39;Epoch: &#39;, &#39;62&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.066811406&#39;)
(&#39;Accuracy: Training :&#39;, 0.98009091209281574)
(&#39;Accuracy: Validation :&#39;, 0.97780000388622279)
(&#39;Epoch: &#39;, &#39;63&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.066251418&#39;)
(&#39;Accuracy: Training :&#39;, 0.9798000026832927)
(&#39;Accuracy: Validation :&#39;, 0.97560000240802769)
(&#39;Epoch: &#39;, &#39;64&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.065685325&#39;)
(&#39;Accuracy: Training :&#39;, 0.98007273077964785)
(&#39;Accuracy: Validation :&#39;, 0.97700000226497652)
(&#39;Epoch: &#39;, &#39;65&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.064872083&#39;)
(&#39;Accuracy: Training :&#39;, 0.98145454970273105)
(&#39;Accuracy: Validation :&#39;, 0.97740000307559971)
(&#39;Epoch: &#39;, &#39;66&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.064185707&#39;)
(&#39;Accuracy: Training :&#39;, 0.98034545757553793)
(&#39;Accuracy: Validation :&#39;, 0.97640000224113466)
(&#39;Epoch: &#39;, &#39;67&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.063485961&#39;)
(&#39;Accuracy: Training :&#39;, 0.98054545819759364)
(&#39;Accuracy: Validation :&#39;, 0.97860000312328344)
(&#39;Epoch: &#39;, &#39;68&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.063271194&#39;)
(&#39;Accuracy: Training :&#39;, 0.98076363953677093)
(&#39;Accuracy: Validation :&#39;, 0.97680000185966487)
(&#39;Epoch: &#39;, &#39;69&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.062271273&#39;)
(&#39;Accuracy: Training :&#39;, 0.98178182233463629)
(&#39;Accuracy: Validation :&#39;, 0.97840000152587892)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.061539926&#39;)
(&#39;Accuracy: Training :&#39;, 0.98218182179060853)
(&#39;Accuracy: Validation :&#39;, 0.97800000429153444)
(&#39;Epoch: &#39;, &#39;71&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.060924345&#39;)
(&#39;Accuracy: Training :&#39;, 0.9821636398813941)
(&#39;Accuracy: Validation :&#39;, 0.97740000367164614)
(&#39;Epoch: &#39;, &#39;72&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.060387546&#39;)
(&#39;Accuracy: Training :&#39;, 0.98230909466743466)
(&#39;Accuracy: Validation :&#39;, 0.97720000386238093)
(&#39;Epoch: &#39;, &#39;73&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.059594849&#39;)
(&#39;Accuracy: Training :&#39;, 0.98138182212005964)
(&#39;Accuracy: Validation :&#39;, 0.97840000391006465)
(&#39;Epoch: &#39;, &#39;74&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.058890018&#39;)
(&#39;Accuracy: Training :&#39;, 0.98310909466309981)
(&#39;Accuracy: Validation :&#39;, 0.97860000371932987)
(&#39;Epoch: &#39;, &#39;75&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.058473589&#39;)
(&#39;Accuracy: Training :&#39;, 0.98307273079048507)
(&#39;Accuracy: Validation :&#39;, 0.97800000309944157)
(&#39;Epoch: &#39;, &#39;76&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.058110452&#39;)
(&#39;Accuracy: Training :&#39;, 0.98265454850413581)
(&#39;Accuracy: Validation :&#39;, 0.97700000524520869)
(&#39;Epoch: &#39;, &#39;77&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.057682903&#39;)
(&#39;Accuracy: Training :&#39;, 0.98312727646394205)
(&#39;Accuracy: Validation :&#39;, 0.97880000352859498)
(&#39;Epoch: &#39;, &#39;78&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.056863414&#39;)
(&#39;Accuracy: Training :&#39;, 0.98170909388498828)
(&#39;Accuracy: Validation :&#39;, 0.97680000126361843)
(&#39;Epoch: &#39;, &#39;79&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.056661195&#39;)
(&#39;Accuracy: Training :&#39;, 0.98363636699589818)
(&#39;Accuracy: Validation :&#39;, 0.97780000388622279)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.056027247&#39;)
(&#39;Accuracy: Training :&#39;, 0.98370909441601151)
(&#39;Accuracy: Validation :&#39;, 0.97980000257492061)
(&#39;Epoch: &#39;, &#39;81&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.055402064&#39;)
(&#39;Accuracy: Training :&#39;, 0.98398182153701785)
(&#39;Accuracy: Validation :&#39;, 0.97760000348091125)
(&#39;Epoch: &#39;, &#39;82&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.055216168&#39;)
(&#39;Accuracy: Training :&#39;, 0.98372727648778391)
(&#39;Accuracy: Validation :&#39;, 0.97880000412464141)
(&#39;Epoch: &#39;, &#39;83&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.054551204&#39;)
(&#39;Accuracy: Training :&#39;, 0.98403636796907945)
(&#39;Accuracy: Validation :&#39;, 0.9786000043153763)
(&#39;Epoch: &#39;, &#39;84&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.053771574&#39;)
(&#39;Accuracy: Training :&#39;, 0.98307273111560123)
(&#39;Accuracy: Validation :&#39;, 0.9792000049352646)
(&#39;Epoch: &#39;, &#39;85&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.053479097&#39;)
(&#39;Accuracy: Training :&#39;, 0.98443636785853994)
(&#39;Accuracy: Validation :&#39;, 0.97780000329017636)
(&#39;Epoch: &#39;, &#39;86&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.052834156&#39;)
(&#39;Accuracy: Training :&#39;, 0.98429091242226685)
(&#39;Accuracy: Validation :&#39;, 0.97740000486373901)
(&#39;Epoch: &#39;, &#39;87&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.052415030&#39;)
(&#39;Accuracy: Training :&#39;, 0.9834363669698889)
(&#39;Accuracy: Validation :&#39;, 0.97920000255107875)
(&#39;Epoch: &#39;, &#39;88&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.052287198&#39;)
(&#39;Accuracy: Training :&#39;, 0.98407273048704325)
(&#39;Accuracy: Validation :&#39;, 0.9784000045061112)
(&#39;Epoch: &#39;, &#39;89&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.051549745&#39;)
(&#39;Accuracy: Training :&#39;, 0.9849818223714828)
(&#39;Accuracy: Validation :&#39;, 0.97760000348091125)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.051364035&#39;)
(&#39;Accuracy: Training :&#39;, 0.98429091328924356)
(&#39;Accuracy: Validation :&#39;, 0.9800000035762787)
(&#39;Epoch: &#39;, &#39;91&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.050561182&#39;)
(&#39;Accuracy: Training :&#39;, 0.98476363962346858)
(&#39;Accuracy: Validation :&#39;, 0.97880000591278071)
(&#39;Epoch: &#39;, &#39;92&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.050710626&#39;)
(&#39;Accuracy: Training :&#39;, 0.98589091273871332)
(&#39;Accuracy: Validation :&#39;, 0.98080000340938567)
(&#39;Epoch: &#39;, &#39;93&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.049755351&#39;)
(&#39;Accuracy: Training :&#39;, 0.984818185838786)
(&#39;Accuracy: Validation :&#39;, 0.97940000534057614)
(&#39;Epoch: &#39;, &#39;94&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.049480785&#39;)
(&#39;Accuracy: Training :&#39;, 0.98627273109826175)
(&#39;Accuracy: Validation :&#39;, 0.98100000500679019)
(&#39;Epoch: &#39;, &#39;95&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.049114088&#39;)
(&#39;Accuracy: Training :&#39;, 0.986272731477564)
(&#39;Accuracy: Validation :&#39;, 0.98160000383853907)
(&#39;Epoch: &#39;, &#39;96&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.048729812&#39;)
(&#39;Accuracy: Training :&#39;, 0.98560000332919029)
(&#39;Accuracy: Validation :&#39;, 0.98000000298023227)
(&#39;Epoch: &#39;, &#39;97&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.048229413&#39;)
(&#39;Accuracy: Training :&#39;, 0.98500000465999948)
(&#39;Accuracy: Validation :&#39;, 0.9800000035762787)
(&#39;Epoch: &#39;, &#39;98&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.048079619&#39;)
(&#39;Accuracy: Training :&#39;, 0.98625455005602403)
(&#39;Accuracy: Validation :&#39;, 0.98020000398159024)
(&#39;Epoch: &#39;, &#39;99&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.047399617&#39;)
(&#39;Accuracy: Training :&#39;, 0.98605454986745666)
(&#39;Accuracy: Validation :&#39;, 0.98000000417232513)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.047101901&#39;)
(&#39;Accuracy: Training :&#39;, 0.98614545876329596)
(&#39;Accuracy: Validation :&#39;, 0.98060000479221343)
Training Finished!
(&#39;Accuracy: Test :&#39;, 0.98290000319480897)
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_text output_error">
<pre>

<span class="ansi-red-fg">NameError</span>Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-7-9f2c4dae9cb4&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># train</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> 
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg"> </span>train<span class="ansi-blue-fg">(</span>X_train<span class="ansi-blue-fg">,</span>y_train<span class="ansi-blue-fg">,</span>X_validation<span class="ansi-blue-fg">,</span>y_validation<span class="ansi-blue-fg">,</span>X_test<span class="ansi-blue-fg">,</span>y_test<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">&#34;lenet5_relu_sgd_0_01_50&#34;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-4-4d975fd7b337&gt;</span> in <span class="ansi-cyan-fg">train</span><span class="ansi-blue-fg">(X_train, y_train, X_validation, y_validation, X_test, y_test, file_save)</span>
<span class="ansi-green-intense-fg ansi-bold">     54</span>             saver<span class="ansi-blue-fg">.</span>save<span class="ansi-blue-fg">(</span>sess<span class="ansi-blue-fg">,</span> file_save<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     55</span>             <span class="ansi-green-fg">print</span><span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Accuracy: Test :&#34;</span><span class="ansi-blue-fg">,</span> evaluate<span class="ansi-blue-fg">(</span>X_test<span class="ansi-blue-fg">,</span>y_test<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 56</span><span class="ansi-red-fg">         </span>training_time <span class="ansi-blue-fg">=</span> time<span class="ansi-blue-fg">.</span>time<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-</span> t0
<span class="ansi-green-intense-fg ansi-bold">     57</span>         <span class="ansi-green-fg">print</span><span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;Training time =&#39;</span><span class="ansi-blue-fg">,</span>training_time<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NameError</span>: global name &#39;t0&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># Gradient Descent</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train     </span>
    
<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;/lenet5_relu_sgd_0_0001_50&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;01&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.304910807&#39;)
(&#39;Accuracy: Training :&#39;, 0.10630909037183632)
(&#39;Accuracy: Validation :&#39;, 0.10879999939352274)
(&#39;Epoch: &#39;, &#39;02&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.284634811&#39;)
(&#39;Accuracy: Training :&#39;, 0.13154545434835282)
(&#39;Accuracy: Validation :&#39;, 0.14060000013560056)
(&#39;Epoch: &#39;, &#39;03&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.270125603&#39;)
(&#39;Accuracy: Training :&#39;, 0.19689090924845501)
(&#39;Accuracy: Validation :&#39;, 0.21759999971836805)
(&#39;Epoch: &#39;, &#39;04&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.256937780&#39;)
(&#39;Accuracy: Training :&#39;, 0.25707272712141277)
(&#39;Accuracy: Validation :&#39;, 0.27740000024437905)
(&#39;Epoch: &#39;, &#39;05&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.242737349&#39;)
(&#39;Accuracy: Training :&#39;, 0.28799999997019765)
(&#39;Accuracy: Validation :&#39;, 0.30159999974071977)
(&#39;Epoch: &#39;, &#39;06&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.226336681&#39;)
(&#39;Accuracy: Training :&#39;, 0.32303636401214381)
(&#39;Accuracy: Validation :&#39;, 0.33120000153779983)
(&#39;Epoch: &#39;, &#39;07&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.206875061&#39;)
(&#39;Accuracy: Training :&#39;, 0.36787272770296442)
(&#39;Accuracy: Validation :&#39;, 0.36560000166296958)
(&#39;Epoch: &#39;, &#39;08&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.183375750&#39;)
(&#39;Accuracy: Training :&#39;, 0.41083636381409383)
(&#39;Accuracy: Validation :&#39;, 0.41540000140666961)
(&#39;Epoch: &#39;, &#39;09&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.154798919&#39;)
(&#39;Accuracy: Training :&#39;, 0.44352727186950769)
(&#39;Accuracy: Validation :&#39;, 0.44559999704360964)
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.119876414&#39;)
(&#39;Accuracy: Training :&#39;, 0.48298181753266939)
(&#39;Accuracy: Validation :&#39;, 0.48960000038146972)
(&#39;Epoch: &#39;, &#39;11&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.076373218&#39;)
(&#39;Accuracy: Training :&#39;, 0.51469090914184401)
(&#39;Accuracy: Validation :&#39;, 0.52119999974966047)
(&#39;Epoch: &#39;, &#39;12&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.021381223&#39;)
(&#39;Accuracy: Training :&#39;, 0.53969090971079736)
(&#39;Accuracy: Validation :&#39;, 0.5492000007629394)
(&#39;Epoch: &#39;, &#39;13&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.951511256&#39;)
(&#39;Accuracy: Training :&#39;, 0.56961818302219569)
(&#39;Accuracy: Validation :&#39;, 0.57380000323057179)
(&#39;Epoch: &#39;, &#39;14&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.863139739&#39;)
(&#39;Accuracy: Training :&#39;, 0.59581818542697218)
(&#39;Accuracy: Validation :&#39;, 0.60340000391006465)
(&#39;Epoch: &#39;, &#39;15&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.753867446&#39;)
(&#39;Accuracy: Training :&#39;, 0.62147273150357329)
(&#39;Accuracy: Validation :&#39;, 0.63380000472068787)
(&#39;Epoch: &#39;, &#39;16&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.624810132&#39;)
(&#39;Accuracy: Training :&#39;, 0.64914546004750517)
(&#39;Accuracy: Validation :&#39;, 0.66500000208616261)
(&#39;Epoch: &#39;, &#39;17&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.482214303&#39;)
(&#39;Accuracy: Training :&#39;, 0.67703636833212588)
(&#39;Accuracy: Validation :&#39;, 0.68840000122785572)
(&#39;Epoch: &#39;, &#39;18&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.335567974&#39;)
(&#39;Accuracy: Training :&#39;, 0.70527273075147112)
(&#39;Accuracy: Validation :&#39;, 0.71520000338554379)
(&#39;Epoch: &#39;, &#39;19&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.194321575&#39;)
(&#39;Accuracy: Training :&#39;, 0.7274727288701317)
(&#39;Accuracy: Validation :&#39;, 0.73599999785423276)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.066165778&#39;)
(&#39;Accuracy: Training :&#39;, 0.74500000065023253)
(&#39;Accuracy: Validation :&#39;, 0.75100000321865079)
(&#39;Epoch: &#39;, &#39;21&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.955652863&#39;)
(&#39;Accuracy: Training :&#39;, 0.76410908910361208)
(&#39;Accuracy: Validation :&#39;, 0.76699999988079071)
(&#39;Epoch: &#39;, &#39;22&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.864037319&#39;)
(&#39;Accuracy: Training :&#39;, 0.77739999803629789)
(&#39;Accuracy: Validation :&#39;, 0.78299999654293062)
(&#39;Epoch: &#39;, &#39;23&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.789874906&#39;)
(&#39;Accuracy: Training :&#39;, 0.78861817809668455)
(&#39;Accuracy: Validation :&#39;, 0.79139999687671658)
(&#39;Epoch: &#39;, &#39;24&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.729926177&#39;)
(&#39;Accuracy: Training :&#39;, 0.79999999490651219)
(&#39;Accuracy: Validation :&#39;, 0.8037999945878983)
(&#39;Epoch: &#39;, &#39;25&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.681154219&#39;)
(&#39;Accuracy: Training :&#39;, 0.80865454034371809)
(&#39;Accuracy: Validation :&#39;, 0.81319999456405645)
(&#39;Epoch: &#39;, &#39;26&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.640940920&#39;)
(&#39;Accuracy: Training :&#39;, 0.81876363125714391)
(&#39;Accuracy: Validation :&#39;, 0.82219999492168427)
(&#39;Epoch: &#39;, &#39;27&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.607445786&#39;)
(&#39;Accuracy: Training :&#39;, 0.82656362999569288)
(&#39;Accuracy: Validation :&#39;, 0.82919999480247497)
(&#39;Epoch: &#39;, &#39;28&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.579045990&#39;)
(&#39;Accuracy: Training :&#39;, 0.83352726632898499)
(&#39;Accuracy: Validation :&#39;, 0.83519999504089359)
(&#39;Epoch: &#39;, &#39;29&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.554601879&#39;)
(&#39;Accuracy: Training :&#39;, 0.84007272118871867)
(&#39;Accuracy: Validation :&#39;, 0.84179999470710754)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.533662499&#39;)
(&#39;Accuracy: Training :&#39;, 0.84614544906399469)
(&#39;Accuracy: Validation :&#39;, 0.84719999432563786)
(&#39;Epoch: &#39;, &#39;31&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.515050853&#39;)
(&#39;Accuracy: Training :&#39;, 0.85009090456095604)
(&#39;Accuracy: Validation :&#39;, 0.85139999687671664)
(&#39;Epoch: &#39;, &#39;32&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.498671643&#39;)
(&#39;Accuracy: Training :&#39;, 0.85443635864691303)
(&#39;Accuracy: Validation :&#39;, 0.85539999604225159)
(&#39;Epoch: &#39;, &#39;33&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.484001935&#39;)
(&#39;Accuracy: Training :&#39;, 0.85798181365836745)
(&#39;Accuracy: Validation :&#39;, 0.86019999742507935)
(&#39;Epoch: &#39;, &#39;34&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.470728683&#39;)
(&#39;Accuracy: Training :&#39;, 0.86192726774649187)
(&#39;Accuracy: Validation :&#39;, 0.86299999475479128)
(&#39;Epoch: &#39;, &#39;35&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.459035010&#39;)
(&#39;Accuracy: Training :&#39;, 0.86423635840415958)
(&#39;Accuracy: Validation :&#39;, 0.86659999549388889)
(&#39;Epoch: &#39;, &#39;36&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.448197698&#39;)
(&#39;Accuracy: Training :&#39;, 0.86767272223125802)
(&#39;Accuracy: Validation :&#39;, 0.87099999427795405)
(&#39;Epoch: &#39;, &#39;37&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.438242000&#39;)
(&#39;Accuracy: Training :&#39;, 0.87021817608313123)
(&#39;Accuracy: Validation :&#39;, 0.87399999380111693)
(&#39;Epoch: &#39;, &#39;38&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.429242099&#39;)
(&#39;Accuracy: Training :&#39;, 0.87318181297995823)
(&#39;Accuracy: Validation :&#39;, 0.87659999489784246)
(&#39;Epoch: &#39;, &#39;39&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.420988601&#39;)
(&#39;Accuracy: Training :&#39;, 0.87456363136118109)
(&#39;Accuracy: Validation :&#39;, 0.87939999520778656)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.413248632&#39;)
(&#39;Accuracy: Training :&#39;, 0.87658181358467446)
(&#39;Accuracy: Validation :&#39;, 0.87979999482631688)
(&#39;Epoch: &#39;, &#39;41&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.406062715&#39;)
(&#39;Accuracy: Training :&#39;, 0.87909090399742129)
(&#39;Accuracy: Validation :&#39;, 0.88479999661445619)
(&#39;Epoch: &#39;, &#39;42&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.399293200&#39;)
(&#39;Accuracy: Training :&#39;, 0.87949090540409092)
(&#39;Accuracy: Validation :&#39;, 0.88759999573230741)
(&#39;Epoch: &#39;, &#39;43&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.392987091&#39;)
(&#39;Accuracy: Training :&#39;, 0.8830363599820571)
(&#39;Accuracy: Validation :&#39;, 0.88939999520778656)
(&#39;Epoch: &#39;, &#39;44&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.386937656&#39;)
(&#39;Accuracy: Training :&#39;, 0.88463635910641059)
(&#39;Accuracy: Validation :&#39;, 0.89159999489784236)
(&#39;Epoch: &#39;, &#39;45&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.381097836&#39;)
(&#39;Accuracy: Training :&#39;, 0.88634545087814331)
(&#39;Accuracy: Validation :&#39;, 0.89239999651908875)
(&#39;Epoch: &#39;, &#39;46&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.375623560&#39;)
(&#39;Accuracy: Training :&#39;, 0.88796363142403689)
(&#39;Accuracy: Validation :&#39;, 0.8949999964237213)
(&#39;Epoch: &#39;, &#39;47&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.370418001&#39;)
(&#39;Accuracy: Training :&#39;, 0.88956363260746008)
(&#39;Accuracy: Validation :&#39;, 0.89619999587535859)
(&#39;Epoch: &#39;, &#39;48&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.365345845&#39;)
(&#39;Accuracy: Training :&#39;, 0.89098181410269306)
(&#39;Accuracy: Validation :&#39;, 0.89679999411106115)
(&#39;Epoch: &#39;, &#39;49&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.360631282&#39;)
(&#39;Accuracy: Training :&#39;, 0.89187272294001141)
(&#39;Accuracy: Validation :&#39;, 0.89779999554157253)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.355862386&#39;)
(&#39;Accuracy: Training :&#39;, 0.89327272295951843)
(&#39;Accuracy: Validation :&#39;, 0.89939999580383301)
(&#39;Epoch: &#39;, &#39;51&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.351463704&#39;)
(&#39;Accuracy: Training :&#39;, 0.89467272319576951)
(&#39;Accuracy: Validation :&#39;, 0.90179999589920046)
(&#39;Epoch: &#39;, &#39;52&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.347276053&#39;)
(&#39;Accuracy: Training :&#39;, 0.89607272310690445)
(&#39;Accuracy: Validation :&#39;, 0.90319999694824216)
(&#39;Epoch: &#39;, &#39;53&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.343134490&#39;)
(&#39;Accuracy: Training :&#39;, 0.897309087135575)
(&#39;Accuracy: Validation :&#39;, 0.90479999423027035)
(&#39;Epoch: &#39;, &#39;54&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.339086946&#39;)
(&#39;Accuracy: Training :&#39;, 0.89814544970338994)
(&#39;Accuracy: Validation :&#39;, 0.9055999952554703)
(&#39;Epoch: &#39;, &#39;55&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.335266866&#39;)
(&#39;Accuracy: Training :&#39;, 0.8988363595984199)
(&#39;Accuracy: Validation :&#39;, 0.90639999508857727)
(&#39;Epoch: &#39;, &#39;56&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.331386482&#39;)
(&#39;Accuracy: Training :&#39;, 0.90012726946310562)
(&#39;Accuracy: Validation :&#39;, 0.90779999673366552)
(&#39;Epoch: &#39;, &#39;57&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.327765220&#39;)
(&#39;Accuracy: Training :&#39;, 0.90070908692750062)
(&#39;Accuracy: Validation :&#39;, 0.90779999792575838)
(&#39;Epoch: &#39;, &#39;58&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.324151160&#39;)
(&#39;Accuracy: Training :&#39;, 0.90245454202998765)
(&#39;Accuracy: Validation :&#39;, 0.90919999599456791)
(&#39;Epoch: &#39;, &#39;59&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.320729823&#39;)
(&#39;Accuracy: Training :&#39;, 0.90270908702503549)
(&#39;Accuracy: Validation :&#39;, 0.91159999608993525)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.317324546&#39;)
(&#39;Accuracy: Training :&#39;, 0.90399999569762834)
(&#39;Accuracy: Validation :&#39;, 0.91079999864101413)
(&#39;Epoch: &#39;, &#39;61&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.314058284&#39;)
(&#39;Accuracy: Training :&#39;, 0.90507272308523001)
(&#39;Accuracy: Validation :&#39;, 0.91019999802112583)
(&#39;Epoch: &#39;, &#39;62&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.311085685&#39;)
(&#39;Accuracy: Training :&#39;, 0.90656363286755304)
(&#39;Accuracy: Validation :&#39;, 0.91279999792575839)
(&#39;Epoch: &#39;, &#39;63&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.307783683&#39;)
(&#39;Accuracy: Training :&#39;, 0.90699999657544228)
(&#39;Accuracy: Validation :&#39;, 0.91359999895095823)
(&#39;Epoch: &#39;, &#39;64&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.305007949&#39;)
(&#39;Accuracy: Training :&#39;, 0.90829090513966304)
(&#39;Accuracy: Validation :&#39;, 0.91599999904632567)
(&#39;Epoch: &#39;, &#39;65&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.302074136&#39;)
(&#39;Accuracy: Training :&#39;, 0.90887272352522075)
(&#39;Accuracy: Validation :&#39;, 0.91639999985694887)
(&#39;Epoch: &#39;, &#39;66&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.299088757&#39;)
(&#39;Accuracy: Training :&#39;, 0.91019999623298642)
(&#39;Accuracy: Validation :&#39;, 0.91619999706745148)
(&#39;Epoch: &#39;, &#39;67&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.296232318&#39;)
(&#39;Accuracy: Training :&#39;, 0.91023635967211292)
(&#39;Accuracy: Validation :&#39;, 0.91559999823570248)
(&#39;Epoch: &#39;, &#39;68&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.293587326&#39;)
(&#39;Accuracy: Training :&#39;, 0.91143635961142455)
(&#39;Accuracy: Validation :&#39;, 0.9187999981641769)
(&#39;Epoch: &#39;, &#39;69&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.290878505&#39;)
(&#39;Accuracy: Training :&#39;, 0.91241817826574501)
(&#39;Accuracy: Validation :&#39;, 0.91859999656677249)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.288301231&#39;)
(&#39;Accuracy: Training :&#39;, 0.91269090538675135)
(&#39;Accuracy: Validation :&#39;, 0.91879999935626988)
(&#39;Epoch: &#39;, &#39;71&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.285603245&#39;)
(&#39;Accuracy: Training :&#39;, 0.91412726922468701)
(&#39;Accuracy: Validation :&#39;, 0.91999999821186063)
(&#39;Epoch: &#39;, &#39;72&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.282977152&#39;)
(&#39;Accuracy: Training :&#39;, 0.91479999721050265)
(&#39;Accuracy: Validation :&#39;, 0.92039999842643738)
(&#39;Epoch: &#39;, &#39;73&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.280560044&#39;)
(&#39;Accuracy: Training :&#39;, 0.91539999652992599)
(&#39;Accuracy: Validation :&#39;, 0.92059999763965605)
(&#39;Epoch: &#39;, &#39;74&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.278124467&#39;)
(&#39;Accuracy: Training :&#39;, 0.91605454266071318)
(&#39;Accuracy: Validation :&#39;, 0.9201999974250793)
(&#39;Epoch: &#39;, &#39;75&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.275837033&#39;)
(&#39;Accuracy: Training :&#39;, 0.91712726939808242)
(&#39;Accuracy: Validation :&#39;, 0.92179999709129334)
(&#39;Epoch: &#39;, &#39;76&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.273410479&#39;)
(&#39;Accuracy: Training :&#39;, 0.91763636101375923)
(&#39;Accuracy: Validation :&#39;, 0.92339999854564669)
(&#39;Epoch: &#39;, &#39;77&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.271114548&#39;)
(&#39;Accuracy: Training :&#39;, 0.91787272507494144)
(&#39;Accuracy: Validation :&#39;, 0.92479999959468839)
(&#39;Epoch: &#39;, &#39;78&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.268986123&#39;)
(&#39;Accuracy: Training :&#39;, 0.91954545178196645)
(&#39;Accuracy: Validation :&#39;, 0.92539999961853026)
(&#39;Epoch: &#39;, &#39;79&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.266719601&#39;)
(&#39;Accuracy: Training :&#39;, 0.91929090543226766)
(&#39;Accuracy: Validation :&#39;, 0.92499999821186063)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.264517579&#39;)
(&#39;Accuracy: Training :&#39;, 0.92092727037993349)
(&#39;Accuracy: Validation :&#39;, 0.92619999766349792)
(&#39;Epoch: &#39;, &#39;81&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.262451955&#39;)
(&#39;Accuracy: Training :&#39;, 0.92110908681696113)
(&#39;Accuracy: Validation :&#39;, 0.92759999871253962)
(&#39;Epoch: &#39;, &#39;82&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.260251935&#39;)
(&#39;Accuracy: Training :&#39;, 0.92161817902868448)
(&#39;Accuracy: Validation :&#39;, 0.92799999833106994)
(&#39;Epoch: &#39;, &#39;83&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.258147757&#39;)
(&#39;Accuracy: Training :&#39;, 0.9223636329174042)
(&#39;Accuracy: Validation :&#39;, 0.92739999711513521)
(&#39;Epoch: &#39;, &#39;84&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.256089916&#39;)
(&#39;Accuracy: Training :&#39;, 0.92252726977521726)
(&#39;Accuracy: Validation :&#39;, 0.92939999759197234)
(&#39;Epoch: &#39;, &#39;85&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.254157862&#39;)
(&#39;Accuracy: Training :&#39;, 0.92365454240278766)
(&#39;Accuracy: Validation :&#39;, 0.92979999661445623)
(&#39;Epoch: &#39;, &#39;86&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.252088365&#39;)
(&#39;Accuracy: Training :&#39;, 0.92327272463928567)
(&#39;Accuracy: Validation :&#39;, 0.93039999723434452)
(&#39;Epoch: &#39;, &#39;87&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.250058794&#39;)
(&#39;Accuracy: Training :&#39;, 0.92456363309513434)
(&#39;Accuracy: Validation :&#39;, 0.93059999763965606)
(&#39;Epoch: &#39;, &#39;88&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.248244226&#39;)
(&#39;Accuracy: Training :&#39;, 0.92514545202255249)
(&#39;Accuracy: Validation :&#39;, 0.93120000004768366)
(&#39;Epoch: &#39;, &#39;89&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.246476134&#39;)
(&#39;Accuracy: Training :&#39;, 0.92532726916399866)
(&#39;Accuracy: Validation :&#39;, 0.93239999830722808)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.244501384&#39;)
(&#39;Accuracy: Training :&#39;, 0.92589090536941177)
(&#39;Accuracy: Validation :&#39;, 0.93299999773502351)
(&#39;Epoch: &#39;, &#39;91&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.242777131&#39;)
(&#39;Accuracy: Training :&#39;, 0.92687272440303459)
(&#39;Accuracy: Validation :&#39;, 0.93239999890327452)
(&#39;Epoch: &#39;, &#39;92&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.240842155&#39;)
(&#39;Accuracy: Training :&#39;, 0.92676363370635295)
(&#39;Accuracy: Validation :&#39;, 0.93439999699592591)
(&#39;Epoch: &#39;, &#39;93&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.239207094&#39;)
(&#39;Accuracy: Training :&#39;, 0.92767272364009512)
(&#39;Accuracy: Validation :&#39;, 0.93359999775886537)
(&#39;Epoch: &#39;, &#39;94&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.237513563&#39;)
(&#39;Accuracy: Training :&#39;, 0.92859999662095849)
(&#39;Accuracy: Validation :&#39;, 0.93539999783039096)
(&#39;Epoch: &#39;, &#39;95&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.235787762&#39;)
(&#39;Accuracy: Training :&#39;, 0.92885454210368068)
(&#39;Accuracy: Validation :&#39;, 0.93539999783039096)
(&#39;Epoch: &#39;, &#39;96&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.234112378&#39;)
(&#39;Accuracy: Training :&#39;, 0.92899999678134915)
(&#39;Accuracy: Validation :&#39;, 0.93799999833106995)
(&#39;Epoch: &#39;, &#39;97&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.232386576&#39;)
(&#39;Accuracy: Training :&#39;, 0.92956363271583209)
(&#39;Accuracy: Validation :&#39;, 0.93599999904632569)
(&#39;Epoch: &#39;, &#39;98&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.230757630&#39;)
(&#39;Accuracy: Training :&#39;, 0.93009090596979316)
(&#39;Accuracy: Validation :&#39;, 0.93579999923706059)
(&#39;Epoch: &#39;, &#39;99&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.229160387&#39;)
(&#39;Accuracy: Training :&#39;, 0.93094545136798512)
(&#39;Accuracy: Validation :&#39;, 0.93819999814033506)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.227510320&#39;)
(&#39;Accuracy: Training :&#39;, 0.9311818157000975)
(&#39;Accuracy: Validation :&#39;, 0.93839999854564671)
Training Finished!
(&#39;Accuracy: Test :&#39;, 0.93679999887943266)
(&#39;Training time =&#39;, 4596.539370059967)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">10</span>


<span class="c1"># Train with Relu and AdamOptimizer</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># AdamOptimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train with AdamOptmiser and learning rate = 0.001</span>

<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_adam_0_001_128&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.021583187&#39;)
(&#39;Accuracy: Training :&#39;, 0.99305454545454541)
(&#39;Accuracy: Validation :&#39;, 0.98640000000000005)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.007799160&#39;)
(&#39;Accuracy: Training :&#39;, 0.99705454545454542)
(&#39;Accuracy: Validation :&#39;, 0.98819999999999997)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.005229142&#39;)
(&#39;Accuracy: Training :&#39;, 0.99903636363636361)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.002041249&#39;)
(&#39;Accuracy: Training :&#39;, 0.99830909090909092)
(&#39;Accuracy: Validation :&#39;, 0.98899999999999999)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003241450&#39;)
(&#39;Accuracy: Training :&#39;, 0.99952727272727271)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000008725&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99239999999999995)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000001082&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99260000000000004)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000000122&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99299999999999999)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000000013&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99260000000000004)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.000000001&#39;)
(&#39;Accuracy: Training :&#39;, 1.0)
(&#39;Accuracy: Validation :&#39;, 0.99280000000000002)
Training Finished!
(&#39;Accuracy: Test :&#39;, 0.99129999999999996)
(&#39;Training time =&#39;, 3109.23579287529)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>


<span class="c1"># Train with Relu and AdamOptimizer</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># AdamOptimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    
    
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train</span>

<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_adam_0_0001_128&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;01&#39;, &#39;  =====&gt; Loss=&#39;, &#39;1.177215875&#39;)
(&#39;Accuracy: Training :&#39;, 0.8860727272380482)
(&#39;Accuracy: Validation :&#39;, 0.89119999999999999)
(&#39;Epoch: &#39;, &#39;02&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.325025455&#39;)
(&#39;Accuracy: Training :&#39;, 0.92427272731607613)
(&#39;Accuracy: Validation :&#39;, 0.92979999999999996)
(&#39;Epoch: &#39;, &#39;03&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.229932647&#39;)
(&#39;Accuracy: Training :&#39;, 0.94041818180951209)
(&#39;Accuracy: Validation :&#39;, 0.9496)
(&#39;Epoch: &#39;, &#39;04&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.181375883&#39;)
(&#39;Accuracy: Training :&#39;, 0.95307272728139703)
(&#39;Accuracy: Validation :&#39;, 0.95820000000000005)
(&#39;Epoch: &#39;, &#39;05&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.148879779&#39;)
(&#39;Accuracy: Training :&#39;, 0.95961818179217251)
(&#39;Accuracy: Validation :&#39;, 0.96679999999999999)
(&#39;Epoch: &#39;, &#39;06&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.127204825&#39;)
(&#39;Accuracy: Training :&#39;, 0.96587272729006679)
(&#39;Accuracy: Validation :&#39;, 0.97119999999999995)
(&#39;Epoch: &#39;, &#39;07&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.111403754&#39;)
(&#39;Accuracy: Training :&#39;, 0.96849090906489976)
(&#39;Accuracy: Validation :&#39;, 0.9728)
(&#39;Epoch: &#39;, &#39;08&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.099788178&#39;)
(&#39;Accuracy: Training :&#39;, 0.97112727276195177)
(&#39;Accuracy: Validation :&#39;, 0.97519999999999996)
(&#39;Epoch: &#39;, &#39;09&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.090840431&#39;)
(&#39;Accuracy: Training :&#39;, 0.97434545450210575)
(&#39;Accuracy: Validation :&#39;, 0.97640000000000005)
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.083712478&#39;)
(&#39;Accuracy: Training :&#39;, 0.97585454542853611)
(&#39;Accuracy: Validation :&#39;, 0.97860000000000003)
(&#39;Epoch: &#39;, &#39;11&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.077736506&#39;)
(&#39;Accuracy: Training :&#39;, 0.97803636359301482)
(&#39;Accuracy: Validation :&#39;, 0.98080000000000001)
(&#39;Epoch: &#39;, &#39;12&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.072761400&#39;)
(&#39;Accuracy: Training :&#39;, 0.9784545454892245)
(&#39;Accuracy: Validation :&#39;, 0.98080000000000001)
(&#39;Epoch: &#39;, &#39;13&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.067759737&#39;)
(&#39;Accuracy: Training :&#39;, 0.9799272727619518)
(&#39;Accuracy: Validation :&#39;, 0.98119999999999996)
(&#39;Epoch: &#39;, &#39;14&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.064158829&#39;)
(&#39;Accuracy: Training :&#39;, 0.98118181813846939)
(&#39;Accuracy: Validation :&#39;, 0.98160000000000003)
(&#39;Epoch: &#39;, &#39;15&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.061014125&#39;)
(&#39;Accuracy: Training :&#39;, 0.98274545451944528)
(&#39;Accuracy: Validation :&#39;, 0.98319999999999996)
(&#39;Epoch: &#39;, &#39;16&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.057396790&#39;)
(&#39;Accuracy: Training :&#39;, 0.98180000003467904)
(&#39;Accuracy: Validation :&#39;, 0.98260000000000003)
(&#39;Epoch: &#39;, &#39;17&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.055720629&#39;)
(&#39;Accuracy: Training :&#39;, 0.98400000001733956)
(&#39;Accuracy: Validation :&#39;, 0.98480000000000001)
(&#39;Epoch: &#39;, &#39;18&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.052916161&#39;)
(&#39;Accuracy: Training :&#39;, 0.98432727276195175)
(&#39;Accuracy: Validation :&#39;, 0.98560000000000003)
(&#39;Epoch: &#39;, &#39;19&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.050829670&#39;)
(&#39;Accuracy: Training :&#39;, 0.98578181819915767)
(&#39;Accuracy: Validation :&#39;, 0.98680000000000001)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.048112791&#39;)
(&#39;Accuracy: Training :&#39;, 0.9866181818355213)
(&#39;Accuracy: Validation :&#39;, 0.98640000000000005)
(&#39;Epoch: &#39;, &#39;21&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.046282670&#39;)
(&#39;Accuracy: Training :&#39;, 0.98685454545454543)
(&#39;Accuracy: Validation :&#39;, 0.98660000000000003)
(&#39;Epoch: &#39;, &#39;22&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.044921353&#39;)
(&#39;Accuracy: Training :&#39;, 0.98756363638097588)
(&#39;Accuracy: Validation :&#39;, 0.98799999999999999)
(&#39;Epoch: &#39;, &#39;23&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.043157315&#39;)
(&#39;Accuracy: Training :&#39;, 0.98650909092643047)
(&#39;Accuracy: Validation :&#39;, 0.98699999999999999)
(&#39;Epoch: &#39;, &#39;24&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.041653507&#39;)
(&#39;Accuracy: Training :&#39;, 0.98816363639831539)
(&#39;Accuracy: Validation :&#39;, 0.98719999999999997)
(&#39;Epoch: &#39;, &#39;25&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.040410894&#39;)
(&#39;Accuracy: Training :&#39;, 0.98778181819915767)
(&#39;Accuracy: Validation :&#39;, 0.98560000000000003)
(&#39;Epoch: &#39;, &#39;26&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.038329164&#39;)
(&#39;Accuracy: Training :&#39;, 0.98710909090909094)
(&#39;Accuracy: Validation :&#39;, 0.98540000000000005)
(&#39;Epoch: &#39;, &#39;27&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.037382370&#39;)
(&#39;Accuracy: Training :&#39;, 0.9897636363636364)
(&#39;Accuracy: Validation :&#39;, 0.98719999999999997)
(&#39;Epoch: &#39;, &#39;28&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.036195018&#39;)
(&#39;Accuracy: Training :&#39;, 0.98998181821649722)
(&#39;Accuracy: Validation :&#39;, 0.98919999999999997)
(&#39;Epoch: &#39;, &#39;29&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.035116222&#39;)
(&#39;Accuracy: Training :&#39;, 0.9895272727272727)
(&#39;Accuracy: Validation :&#39;, 0.98819999999999997)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.033862028&#39;)
(&#39;Accuracy: Training :&#39;, 0.99080000000000001)
(&#39;Accuracy: Validation :&#39;, 0.98819999999999997)
(&#39;Epoch: &#39;, &#39;31&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.032727130&#39;)
(&#39;Accuracy: Training :&#39;, 0.9891090909264304)
(&#39;Accuracy: Validation :&#39;, 0.98660000000000003)
(&#39;Epoch: &#39;, &#39;32&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.031708853&#39;)
(&#39;Accuracy: Training :&#39;, 0.98950909092643047)
(&#39;Accuracy: Validation :&#39;, 0.98699999999999999)
(&#39;Epoch: &#39;, &#39;33&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.031025442&#39;)
(&#39;Accuracy: Training :&#39;, 0.99143636363636367)
(&#39;Accuracy: Validation :&#39;, 0.98780000000000001)
(&#39;Epoch: &#39;, &#39;34&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.030169315&#39;)
(&#39;Accuracy: Training :&#39;, 0.9918181818355214)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;35&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.028863116&#39;)
(&#39;Accuracy: Training :&#39;, 0.99163636365370322)
(&#39;Accuracy: Validation :&#39;, 0.98640000000000005)
(&#39;Epoch: &#39;, &#39;36&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.028281779&#39;)
(&#39;Accuracy: Training :&#39;, 0.99221818183552135)
(&#39;Accuracy: Validation :&#39;, 0.98819999999999997)
(&#39;Epoch: &#39;, &#39;37&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.027293235&#39;)
(&#39;Accuracy: Training :&#39;, 0.99140000001733952)
(&#39;Accuracy: Validation :&#39;, 0.98839999999999995)
(&#39;Epoch: &#39;, &#39;38&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.026477943&#39;)
(&#39;Accuracy: Training :&#39;, 0.98996363638097584)
(&#39;Accuracy: Validation :&#39;, 0.98699999999999999)
(&#39;Epoch: &#39;, &#39;39&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.026335988&#39;)
(&#39;Accuracy: Training :&#39;, 0.99314545454545455)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.025100866&#39;)
(&#39;Accuracy: Training :&#39;, 0.99365454545454546)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;41&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.024233372&#39;)
(&#39;Accuracy: Training :&#39;, 0.99270909092643045)
(&#39;Accuracy: Validation :&#39;, 0.98780000000000001)
(&#39;Epoch: &#39;, &#39;42&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.023791824&#39;)
(&#39;Accuracy: Training :&#39;, 0.99329090909090911)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;43&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.022768544&#39;)
(&#39;Accuracy: Training :&#39;, 0.99450909092643047)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;44&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.021836878&#39;)
(&#39;Accuracy: Training :&#39;, 0.99414545454545455)
(&#39;Accuracy: Validation :&#39;, 0.98880000000000001)
(&#39;Epoch: &#39;, &#39;45&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.021260503&#39;)
(&#39;Accuracy: Training :&#39;, 0.99496363636363638)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;46&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.020797339&#39;)
(&#39;Accuracy: Training :&#39;, 0.99465454545454546)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;47&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.019956226&#39;)
(&#39;Accuracy: Training :&#39;, 0.99387272727272724)
(&#39;Accuracy: Validation :&#39;, 0.98880000000000001)
(&#39;Epoch: &#39;, &#39;48&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.019794081&#39;)
(&#39;Accuracy: Training :&#39;, 0.99483636363636363)
(&#39;Accuracy: Validation :&#39;, 0.98860000000000003)
(&#39;Epoch: &#39;, &#39;49&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.019101596&#39;)
(&#39;Accuracy: Training :&#39;, 0.99454545454545451)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.018237076&#39;)
(&#39;Accuracy: Training :&#39;, 0.99543636365370314)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;51&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.017585410&#39;)
(&#39;Accuracy: Training :&#39;, 0.99503636363636361)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;52&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.017265051&#39;)
(&#39;Accuracy: Training :&#39;, 0.99598181818181819)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;53&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.016555338&#39;)
(&#39;Accuracy: Training :&#39;, 0.99634545454545453)
(&#39;Accuracy: Validation :&#39;, 0.99119999999999997)
(&#39;Epoch: &#39;, &#39;54&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.016613374&#39;)
(&#39;Accuracy: Training :&#39;, 0.99641818181818187)
(&#39;Accuracy: Validation :&#39;, 0.99080000000000001)
(&#39;Epoch: &#39;, &#39;55&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.015521345&#39;)
(&#39;Accuracy: Training :&#39;, 0.99580000000000002)
(&#39;Accuracy: Validation :&#39;, 0.99039999999999995)
(&#39;Epoch: &#39;, &#39;56&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.015414851&#39;)
(&#39;Accuracy: Training :&#39;, 0.99538181818181815)
(&#39;Accuracy: Validation :&#39;, 0.98760000000000003)
(&#39;Epoch: &#39;, &#39;57&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.014821897&#39;)
(&#39;Accuracy: Training :&#39;, 0.99585454545454544)
(&#39;Accuracy: Validation :&#39;, 0.98899999999999999)
(&#39;Epoch: &#39;, &#39;58&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.014180185&#39;)
(&#39;Accuracy: Training :&#39;, 0.99696363636363639)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;59&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.013456027&#39;)
(&#39;Accuracy: Training :&#39;, 0.99632727272727273)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.013656984&#39;)
(&#39;Accuracy: Training :&#39;, 0.99705454545454542)
(&#39;Accuracy: Validation :&#39;, 0.98919999999999997)
(&#39;Epoch: &#39;, &#39;61&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.013717350&#39;)
(&#39;Accuracy: Training :&#39;, 0.99710909090909094)
(&#39;Accuracy: Validation :&#39;, 0.98899999999999999)
(&#39;Epoch: &#39;, &#39;62&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.012834111&#39;)
(&#39;Accuracy: Training :&#39;, 0.99714545454545456)
(&#39;Accuracy: Validation :&#39;, 0.98919999999999997)
(&#39;Epoch: &#39;, &#39;63&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.012006139&#39;)
(&#39;Accuracy: Training :&#39;, 0.99767272727272727)
(&#39;Accuracy: Validation :&#39;, 0.99039999999999995)
(&#39;Epoch: &#39;, &#39;64&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.011517940&#39;)
(&#39;Accuracy: Training :&#39;, 0.99690909090909086)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;65&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.011777667&#39;)
(&#39;Accuracy: Training :&#39;, 0.99723636363636359)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;66&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.011276234&#39;)
(&#39;Accuracy: Training :&#39;, 0.99783636363636363)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;67&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.010553278&#39;)
(&#39;Accuracy: Training :&#39;, 0.99681818181818183)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;68&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.010642779&#39;)
(&#39;Accuracy: Training :&#39;, 0.99769090909090907)
(&#39;Accuracy: Validation :&#39;, 0.98919999999999997)
(&#39;Epoch: &#39;, &#39;69&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.009547735&#39;)
(&#39;Accuracy: Training :&#39;, 0.99805454545454542)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.009450031&#39;)
(&#39;Accuracy: Training :&#39;, 0.99858181818181824)
(&#39;Accuracy: Validation :&#39;, 0.99080000000000001)
(&#39;Epoch: &#39;, &#39;71&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.009765223&#39;)
(&#39;Accuracy: Training :&#39;, 0.99836363636363634)
(&#39;Accuracy: Validation :&#39;, 0.98919999999999997)
(&#39;Epoch: &#39;, &#39;72&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.008922862&#39;)
(&#39;Accuracy: Training :&#39;, 0.99847272727272729)
(&#39;Accuracy: Validation :&#39;, 0.99080000000000001)
(&#39;Epoch: &#39;, &#39;73&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.009253193&#39;)
(&#39;Accuracy: Training :&#39;, 0.99838181819915772)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;74&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.008319766&#39;)
(&#39;Accuracy: Training :&#39;, 0.99674545454545449)
(&#39;Accuracy: Validation :&#39;, 0.98880000000000001)
(&#39;Epoch: &#39;, &#39;75&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.008643710&#39;)
(&#39;Accuracy: Training :&#39;, 0.99861818181818185)
(&#39;Accuracy: Validation :&#39;, 0.98799999999999999)
(&#39;Epoch: &#39;, &#39;76&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.007822594&#39;)
(&#39;Accuracy: Training :&#39;, 0.99700000001733957)
(&#39;Accuracy: Validation :&#39;, 0.98760000000000003)
(&#39;Epoch: &#39;, &#39;77&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.008012139&#39;)
(&#39;Accuracy: Training :&#39;, 0.99839999999999995)
(&#39;Accuracy: Validation :&#39;, 0.98860000000000003)
(&#39;Epoch: &#39;, &#39;78&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.007595876&#39;)
(&#39;Accuracy: Training :&#39;, 0.99856363636363632)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;79&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.006681723&#39;)
(&#39;Accuracy: Training :&#39;, 0.99825454545454551)
(&#39;Accuracy: Validation :&#39;, 0.99160000000000004)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.007181692&#39;)
(&#39;Accuracy: Training :&#39;, 0.99885454545454544)
(&#39;Accuracy: Validation :&#39;, 0.98919999999999997)
(&#39;Epoch: &#39;, &#39;81&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.006817734&#39;)
(&#39;Accuracy: Training :&#39;, 0.99821818181818178)
(&#39;Accuracy: Validation :&#39;, 0.98699999999999999)
(&#39;Epoch: &#39;, &#39;82&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.006904539&#39;)
(&#39;Accuracy: Training :&#39;, 0.99821818181818178)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;83&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.006410090&#39;)
(&#39;Accuracy: Training :&#39;, 0.99896363636363639)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;84&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.005638718&#39;)
(&#39;Accuracy: Training :&#39;, 0.99818181818181817)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;85&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.005645228&#39;)
(&#39;Accuracy: Training :&#39;, 0.99901818181818181)
(&#39;Accuracy: Validation :&#39;, 0.99139999999999995)
(&#39;Epoch: &#39;, &#39;86&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.005621098&#39;)
(&#39;Accuracy: Training :&#39;, 0.99945454545454548)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;87&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.004919561&#39;)
(&#39;Accuracy: Training :&#39;, 0.99943636363636368)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;88&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.006032514&#39;)
(&#39;Accuracy: Training :&#39;, 0.99923636363636359)
(&#39;Accuracy: Validation :&#39;, 0.99099999999999999)
(&#39;Epoch: &#39;, &#39;89&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.005008055&#39;)
(&#39;Accuracy: Training :&#39;, 0.99954545454545451)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.004653532&#39;)
(&#39;Accuracy: Training :&#39;, 0.99939999999999996)
(&#39;Accuracy: Validation :&#39;, 0.99019999999999997)
(&#39;Epoch: &#39;, &#39;91&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.004388396&#39;)
(&#39;Accuracy: Training :&#39;, 0.99827272727272731)
(&#39;Accuracy: Validation :&#39;, 0.98939999999999995)
(&#39;Epoch: &#39;, &#39;92&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.004178033&#39;)
(&#39;Accuracy: Training :&#39;, 0.99874545454545449)
(&#39;Accuracy: Validation :&#39;, 0.98980000000000001)
(&#39;Epoch: &#39;, &#39;93&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.005107042&#39;)
(&#39;Accuracy: Training :&#39;, 0.99912727272727275)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;94&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003983323&#39;)
(&#39;Accuracy: Training :&#39;, 0.99929090909090912)
(&#39;Accuracy: Validation :&#39;, 0.99080000000000001)
(&#39;Epoch: &#39;, &#39;95&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003874471&#39;)
(&#39;Accuracy: Training :&#39;, 0.99954545454545451)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;96&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003997780&#39;)
(&#39;Accuracy: Training :&#39;, 0.99960000000000004)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;97&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003565362&#39;)
(&#39;Accuracy: Training :&#39;, 0.99943636363636368)
(&#39;Accuracy: Validation :&#39;, 0.98999999999999999)
(&#39;Epoch: &#39;, &#39;98&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003773787&#39;)
(&#39;Accuracy: Training :&#39;, 0.99960000000000004)
(&#39;Accuracy: Validation :&#39;, 0.99080000000000001)
(&#39;Epoch: &#39;, &#39;99&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003473910&#39;)
(&#39;Accuracy: Training :&#39;, 0.99872727272727269)
(&#39;Accuracy: Validation :&#39;, 0.98919999999999997)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003520420&#39;)
(&#39;Accuracy: Training :&#39;, 0.99956363636363632)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
Training Finished!
(&#39;Accuracy: Test :&#39;, 0.98760000000000003)
(&#39;Training time =&#39;, 3934.6936600208282)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>


<span class="c1"># Train with Relu and AdamOptimizer</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># AdamOptimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    
    
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train</span>

<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_adam_0_001_50&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;01&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.440433309&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163635752417822)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;02&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310918952&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817496771166)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;03&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311620893&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454540934075)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;04&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311954211&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909035517411)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;05&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310939533&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909032388167)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;06&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311514097&#39;)
(&#39;Accuracy: Training :&#39;, 0.09798181761056185)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;07&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310833327&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163635769350958)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;08&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311375509&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909032469446)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;09&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310998598&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545410356739)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311635586&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909019180319)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;11&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310705713&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909030437469)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;12&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312348184&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545415436679)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;13&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311146498&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817594983368)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;14&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310793767&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817458163603)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;15&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311761330&#39;)
(&#39;Accuracy: Training :&#39;, 0.1039090903408148)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;16&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310946202&#39;)
(&#39;Accuracy: Training :&#39;, 0.1039090902900154)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;17&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310869606&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490908539430667)
(&#39;Accuracy: Validation :&#39;, 0.10699999947100877)
(&#39;Epoch: &#39;, &#39;18&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310812815&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163635650818996)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;19&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311390065&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544782638543)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310483623&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908457474269)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;21&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311335705&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545403922146)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;22&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311864781&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817483224654)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;23&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311275742&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817498803137)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;24&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310276631&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544816504828)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;25&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311364460&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909044918689)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;26&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310733565&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490908305753367)
(&#39;Accuracy: Validation :&#39;, 0.10699999947100877)
(&#39;Epoch: &#39;, &#39;27&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310390568&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545404938134)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;28&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311569481&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909022648226)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;29&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310471588&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545402228832)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311317857&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909024937586)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;31&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311299573&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454539951953)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;32&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311060478&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817485256625)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;33&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312078666&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545404938134)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;34&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312022356&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817546215919)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;35&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311250557&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909037468109)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;36&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311280824&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817537410699)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;37&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311505314&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908562459734)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;38&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311185836&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490908343006263)
(&#39;Accuracy: Validation :&#39;, 0.10699999947100877)
(&#39;Epoch: &#39;, &#39;39&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311060181&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545400874181)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312535131&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545403244821)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;41&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310794476&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909035436131)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;42&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311568014&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817512349648)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;43&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310534100&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544752158897)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;44&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311984426&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909021550959)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;45&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311200940&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545395116914)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;46&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312248312&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909020196308)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;47&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311345819&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909038145434)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;48&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311636206&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909030694853)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;49&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311109961&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908349102194)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311983453&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545399180867)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;51&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311460480&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817546215919)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;52&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310828179&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909026373517)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;53&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310667621&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817527250812)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;54&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311621748&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544782638543)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;55&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312639509&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545410018075)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;56&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311598808&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545397487554)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;57&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311506323&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545408324761)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;58&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311281988&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909041952003)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;59&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310837942&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163635688071905)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311014860&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909022648226)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;61&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311180351&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545403922146)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;62&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312240515&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909035097469)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;63&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311150987&#39;)
(&#39;Accuracy: Training :&#39;, 0.09898181759159673)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;64&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311511780&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545403244821)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;65&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311982117&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908457474269)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;66&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312239888&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545403244821)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;67&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310629334&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817461550241)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;68&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311602223&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545402567495)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;69&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310945852&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545406292785)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310359361&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544782638543)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;71&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312570525&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908372808592)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;72&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311529822&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545402228832)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;73&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312034192&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545410695401)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;74&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311694413&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545399180867)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;75&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311388138&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545415436679)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;76&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310915991&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909027985551)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;77&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310735503&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909032469446)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;78&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312169177&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545414759355)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;79&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311134229&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545400196856)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312185212&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163635701618416)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;81&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310604569&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545392068949)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;82&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311766173&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545394778252)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;83&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311542578&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909026712179)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;84&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311940652&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909032130784)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;85&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311255928&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545401551507)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;86&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312445897&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544806344941)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;87&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311989788&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545410018075)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;88&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312279022&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817590242076)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;89&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310961669&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909033742818)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311412395&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545413066041)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;91&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312411799&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490908400578931)
(&#39;Accuracy: Validation :&#39;, 0.10699999947100877)
(&#39;Epoch: &#39;, &#39;92&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311162815&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909035856073)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;93&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311262438&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454540189017)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;94&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312338151&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544833437963)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;95&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310913602&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817584823481)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;96&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311502828&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817536056046)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;97&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311713371&#39;)
(&#39;Accuracy: Training :&#39;, 0.090672726604071524)
(&#39;Accuracy: Validation :&#39;, 0.086799999773502348)
(&#39;Epoch: &#39;, &#39;98&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312826641&#39;)
(&#39;Accuracy: Training :&#39;, 0.09798181744800373)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;99&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311573660&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544941810039)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311883049&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545409002088)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
Training Finished!
(&#39;Accuracy: Test :&#39;, 0.11349999938160181)
(&#39;Training time =&#39;, 4614.849516868591)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>


<span class="c1"># Train with Relu and AdamOptimizer</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># AdamOptimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    
    
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train</span>

<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_adam_0_0001_50&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;01&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.515899218&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909045934676)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;02&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311493361&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817567890346)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;03&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310970140&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817503544414)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;04&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310968520&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545398842205)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;05&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312137067&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545415775342)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;06&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311186916&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163635630499236)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;07&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311194516&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545416114006)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;08&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311070817&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454540189017)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;09&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312410130&#39;)
(&#39;Accuracy: Training :&#39;, 0.090672726556658742)
(&#39;Accuracy: Validation :&#39;, 0.086799999773502348)
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312131630&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909026034853)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;11&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311592366&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909032130784)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;12&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310937680&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545404260808)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;13&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312748240&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545407308774)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;14&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311843728&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545409002088)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;15&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311517506&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545405954123)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;16&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311425164&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490908407352194)
(&#39;Accuracy: Validation :&#39;, 0.10699999947100877)
(&#39;Epoch: &#39;, &#39;17&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311919244&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545403244821)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;18&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311504203&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908457474269)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;19&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311615171&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908457474269)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311408154&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909030098806)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;21&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311136865&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545404938134)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;22&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312324191&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544813118204)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;23&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311431649&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817542829294)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;24&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311361223&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817517090925)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;25&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310677601&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544782638543)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;26&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311257759&#39;)
(&#39;Accuracy: Training :&#39;, 0.09945454486391761)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;27&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311199689&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909032388167)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;28&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312727105&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545413404703)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;29&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311067799&#39;)
(&#39;Accuracy: Training :&#39;, 0.1025090902061625)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311082118&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544704746115)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;31&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311279039&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545415098017)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;32&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311509043&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909027646889)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;33&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311801491&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490908349779525)
(&#39;Accuracy: Validation :&#39;, 0.10699999947100877)
(&#39;Epoch: &#39;, &#39;34&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311313542&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909040597352)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;35&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312009454&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163635623725974)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;36&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311330005&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909039161422)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;37&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311166611&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909036872062)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;38&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311748385&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909029760144)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;39&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311515415&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545410356739)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310614504&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545393423601)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;41&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311259513&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545410695401)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;42&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311681296&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817496771166)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;43&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311313783&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909025696191)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;44&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311375689&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545396810228)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;45&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311630016&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908454087644)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;46&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311602494&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817613948474)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;47&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311341529&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909026712179)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;48&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311577839&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908511660313)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;49&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311403274&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545404260808)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311234431&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909025276249)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;51&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310935495&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817456131632)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;52&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311391600&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817498803137)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;53&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311949233&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817695227541)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;54&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310833153&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545416114006)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;55&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312827782&#39;)
(&#39;Accuracy: Training :&#39;, 0.1025090902434154)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;56&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311126813&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817522509534)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;57&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311860124&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545414420691)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;58&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311459355&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909037549387)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;59&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311332392&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163635830310251)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310490746&#39;)
(&#39;Accuracy: Training :&#39;, 0.1025090901824561)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;61&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311369725&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817517090925)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;62&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311476410&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908420221374)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;63&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311500555&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545412727377)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;64&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311884204&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545404260808)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;65&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311055228&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545395116914)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;66&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312390127&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909036790782)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;67&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312015006&#39;)
(&#39;Accuracy: Training :&#39;, 0.09916363570500504)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;68&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310677317&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909027646889)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;69&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311528013&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454539951953)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311188720&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545407986099)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;71&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311217572&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454538597302)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;72&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310659448&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909031710842)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;73&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311910958&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817486611279)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;74&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311153768&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909033742818)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;75&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310707490&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454540189017)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;76&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312089824&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545397148891)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;77&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311831520&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545402567495)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;78&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312409909&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817506931039)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;79&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310860734&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909026373517)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311458128&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817515736272)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;81&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311186753&#39;)
(&#39;Accuracy: Training :&#39;, 0.10250909045338631)
(&#39;Accuracy: Validation :&#39;, 0.098599999248981482)
(&#39;Epoch: &#39;, &#39;82&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312275267&#39;)
(&#39;Accuracy: Training :&#39;, 0.1123454540697011)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;83&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311802482&#39;)
(&#39;Accuracy: Training :&#39;, 0.099454544782638543)
(&#39;Accuracy: Validation :&#39;, 0.097599999420344835)
(&#39;Epoch: &#39;, &#39;84&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311125259&#39;)
(&#39;Accuracy: Training :&#39;, 0.10390909024260261)
(&#39;Accuracy: Validation :&#39;, 0.10999999959021807)
(&#39;Epoch: &#39;, &#39;85&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312225983&#39;)
(&#39;Accuracy: Training :&#39;, 0.097981817502189761)
(&#39;Accuracy: Validation :&#39;, 0.092399998940527445)
(&#39;Epoch: &#39;, &#39;86&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311563065&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490908363326036)
(&#39;Accuracy: Validation :&#39;, 0.10699999947100877)
(&#39;Epoch: &#39;, &#39;87&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311246041&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545422548597)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;88&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.310870305&#39;)
(&#39;Accuracy: Training :&#39;, 0.098981817615303128)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;89&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311233084&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490908569910314)
(&#39;Accuracy: Validation :&#39;, 0.10699999947100877)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311423243&#39;)
(&#39;Accuracy: Training :&#39;, 0.098490908454087644)
(&#39;Accuracy: Validation :&#39;, 0.1001999993249774)
(&#39;Epoch: &#39;, &#39;91&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311583435&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545409679413)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;92&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311317084&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545397148891)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;93&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312053209&#39;)
(&#39;Accuracy: Training :&#39;, 0.099163635769350958)
(&#39;Accuracy: Validation :&#39;, 0.098999999240040784)
(&#39;Epoch: &#39;, &#39;94&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311214040&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545388682322)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;95&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311709119&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545412050052)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;96&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312869230&#39;)
(&#39;Accuracy: Training :&#39;, 0.09898181744935837)
(&#39;Accuracy: Validation :&#39;, 0.095799999311566353)
(&#39;Epoch: &#39;, &#39;97&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311418647&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545412727377)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;98&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.311728393&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545398503543)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
(&#39;Epoch: &#39;, &#39;99&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312154865&#39;)
(&#39;Accuracy: Training :&#39;, 0.096490908607163209)
(&#39;Accuracy: Validation :&#39;, 0.10699999947100877)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;2.312322676&#39;)
(&#39;Accuracy: Training :&#39;, 0.11234545391052961)
(&#39;Accuracy: Validation :&#39;, 0.11259999930858612)
Training Finished!
(&#39;Accuracy: Test :&#39;, 0.11349999938160181)
(&#39;Training time =&#39;, 4599.537647008896)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<table>
<thead><tr>
<th>Optimizer</th>
<th style="text-align:left">Gradient Descent</th>
<th>Adam Optimizer</th>
<th>Adam Optimizer</th>
<th>Adam Optimizer</th>
<th>Adam Optimizer</th>
<th>Adam Optimizer</th>
<th>Gradient Descent</th>
<th>Gradient Descent</th>
<th>Gradient Descent</th>
<th>Gradient Descent</th>
</tr>
</thead>
<tbody>
<tr>
<td>Training epochs</td>
<td style="text-align:left">100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100 </td>
</tr>
<tr>
<td>Batch size</td>
<td style="text-align:left">128</td>
<td>128</td>
<td>50</td>
<td>128</td>
<td>128</td>
<td>50</td>
<td>128</td>
<td>50</td>
<td>128</td>
<td>50</td>
</tr>
<tr>
<td>Learning rate</td>
<td style="text-align:left">0.1</td>
<td>0.1</td>
<td>0.0001</td>
<td>0.0001</td>
<td>0.001</td>
<td>0.001</td>
<td>0.0001</td>
<td>0.0001</td>
<td>0.001</td>
<td>0.001</td>
</tr>
<tr>
<td>Validation Accuracy</td>
<td style="text-align:left">0.990</td>
<td>0.0923</td>
<td>0.112</td>
<td>0.989</td>
<td>0.992</td>
<td>0.112</td>
<td>0.884</td>
<td>0.938</td>
<td>0.975</td>
<td>0.980</td>
</tr>
<tr>
<td>Testing Accuracy</td>
<td style="text-align:left">0.989</td>
<td>0.0974</td>
<td>0.11</td>
<td>0.987</td>
<td>0.991</td>
<td>0.113</td>
<td>0.883</td>
<td>0.936</td>
<td>0.976</td>
<td>0.982</td>
</tr>
<tr>
<td>Training Time</td>
<td style="text-align:left">3889</td>
<td>3949</td>
<td>4599</td>
<td>3934</td>
<td>3109</td>
<td>4614</td>
<td></td>
<td>4596</td>
<td>3913</td>
<td></td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>


<span class="c1"># Gradient Descent optimizer</span>
<span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># learning_rate,batch_size : (0.1,128),(0.001,128),(0.0001,128),(0.001,50),(0.0001,50)</span>
<span class="n">test_accuracy_sgd</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.989</span><span class="p">,</span><span class="mf">0.976</span><span class="p">,</span><span class="mf">0.883</span><span class="p">,</span><span class="mf">0.982</span><span class="p">,</span><span class="mf">0.936</span><span class="p">]</span>

<span class="c1"># AdamOptimizer</span>
<span class="n">test_accuracy_adam</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0974</span><span class="p">,</span><span class="mf">0.991</span><span class="p">,</span><span class="mf">0.988</span><span class="p">,</span><span class="mf">0.113</span><span class="p">,</span><span class="mf">0.113</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">test_accuracy_sgd</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">test_accuracy_adam</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Test accuracy for SGD and AdamOptimizer&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="alert alert-success">
We can see that when we decrease the learning rate, the test accuracy tends to decrease. Moreover, we obtained better results for a batch size of 50 rather than 128. 
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="alert alert-success">
When we compare the two optimizer, we remark that the accuracy for the Adamoptimizer is sometimes too low for the training, testing and validation samples (about 11% of accuracy). But when AdamOptimizer has a good accuracy, it becomes better than the SGD.
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="alert alert-success">

Yes, 99% was reached for test accuracy. It was obtained for Adam Optimizer, for a learning rate of 0.001 and a batch size of 128. Moreover, we almost reached 99% as we had in many cases an accuracy superior to 98%.


</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><b> Question 2.2.2 </b>  What about applying a dropout layer on the Fully conntected layer and then retraining the model with the best Optimizer and parameters(Learning rate and Batsh size) obtained in <em>Question 2.2.1</em>  ? (probability to keep units=0.75). For this stage ensure that the keep prob is set to 1.0 to evaluate the 
performance of the network including all nodes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="alert alert-success">

The Optimizer we retained is the AdamOptimizer and a learning rate of 0.001 and a batch size of 128.


</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># The function Lenet5 with Relu</span>

<span class="kn">from</span> <span class="nn">tensorflow.contrib.layers</span> <span class="kn">import</span> <span class="n">flatten</span>


<span class="k">def</span> <span class="nf">LeNet5_Model</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>    
    <span class="c1"># your inmplementation goes here</span>
    <span class="c1">#Layer 1: Convolutional</span>
    <span class="n">layer1_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
    <span class="n">layer1_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">6</span><span class="p">,))</span>
    <span class="n">data2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="n">layer1_weights</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">layer1_bias</span>
    <span class="c1">#Activation. sigmoid</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv1</span><span class="p">)</span>
    <span class="c1">#Pooling</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">conv1</span> <span class="p">,</span><span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    
    
    <span class="c1">#Layer 2: Convolutional</span>
    <span class="n">layer2_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">16</span><span class="p">))</span>
    <span class="n">layer2_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">16</span><span class="p">,))</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="n">layer2_weights</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;VALID&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">layer2_bias</span>
    <span class="c1">#Activation. relu</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>
    <span class="c1">#Pooling</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">conv2</span> <span class="p">,</span><span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    
    <span class="c1">#Flatten</span>
    <span class="n">conv_flat</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>
    
    <span class="c1">#Layer 3: Fully Connected</span>
    <span class="n">layer3_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">400</span><span class="p">,</span> <span class="mi">120</span><span class="p">))</span>
    <span class="n">layer3_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">120</span><span class="p">,))</span>
    <span class="n">layer3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span><span class="n">conv_flat</span><span class="p">,</span><span class="n">layer3_weights</span><span class="p">,</span><span class="n">layer3_bias</span><span class="p">)</span>

    <span class="c1">#Activation. relu</span>
    
    <span class="n">layer3_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">layer3</span><span class="p">)</span>
    
    <span class="c1">#Layer 4: Fully Connected</span>
    <span class="n">layer4_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">))</span>
    <span class="n">layer4_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">84</span><span class="p">,))</span>
    <span class="n">layer4</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span> <span class="n">layer3_out</span><span class="p">,</span><span class="n">layer4_weights</span><span class="p">,</span><span class="n">layer4_bias</span><span class="p">)</span>

    <span class="c1">#Activation. relu</span>
    
    <span class="n">layer4_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">layer4</span><span class="p">)</span>
    
    <span class="c1">#Layer 5: Fully Connected</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer4_out</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">layer5_weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">((</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">layer5_bias</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">((</span><span class="mi">10</span><span class="p">,))</span>
    <span class="n">layer5</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span> <span class="n">dropout</span><span class="p">,</span><span class="n">layer5_weights</span><span class="p">,</span><span class="n">layer5_bias</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">layer5</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">layer5</span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Train with Relu and AdamOptimizer</span>

<span class="c1"># tf Graph Input:  mnist data image of shape 28*28=784</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;InputData&#39;</span><span class="p">)</span>
<span class="c1"># 0-9 digits recognition,  10 classes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LabelData&#39;</span><span class="p">)</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">&#39;log_files/&#39;</span>  <span class="c1"># useful for tensorboard</span>

<span class="c1"># Set model weights</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bias&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">):</span>
    <span class="c1"># Model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">LeNet5_Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">):</span>
    <span class="c1"># Minimize error using cross entropy</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">):</span>
    <span class="c1"># AdamOptimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy_operation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span><span class="n">proba</span><span class="p">):</span>
    <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
    <span class="n">total_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_session</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">X_data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">y_data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy_operation</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">batch_y</span><span class="p">,</span><span class="n">keep_prob</span><span class="p">:</span><span class="n">proba</span><span class="p">})</span>
        <span class="n">total_accuracy</span> <span class="o">+=</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">total_accuracy</span> <span class="o">/</span> <span class="n">num_examples</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">import</span> <span class="nn">time</span>



<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">file_save</span><span class="p">):</span>

        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">training_acc</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">validation_acc</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="c1"># Initializing the variables</span>
        <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
        <span class="c1"># Create a summary to monitor cost tensor</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
        <span class="c1"># Create a summary to monitor accuracy tensor</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;Traning_Accuracy&quot;</span><span class="p">,</span> <span class="n">training_acc</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;Validation_Accuracy&quot;</span><span class="p">,</span> <span class="n">validation_acc</span><span class="p">)</span>
        <span class="c1"># Merge all summaries into a single op</span>
        <span class="n">merged_summary_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
        

        
        <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;Start Training!&quot;</span><span class="p">)</span>
        
        <span class="c1"># Launch the graph for training</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
            <span class="c1"># op to write logs to Tensorboard</span>
            <span class="c1"># Training cycle</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_epochs</span><span class="p">):</span>
                <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
                <span class="n">avg_cost</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
                <span class="n">total_batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_examples</span><span class="o">/</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="c1"># Loop over all batches</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">num_examples</span><span class="p">,</span><span class="n">batch_size</span><span class="p">):</span>
                    <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                    <span class="c1"># Run optimization op (backprop), cost op (to get loss value)</span>
                    <span class="c1"># and summary nodes</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">summary</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">merged_summary_op</span><span class="p">],</span>
                                             <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">batch_ys</span><span class="p">,</span><span class="n">keep_prob</span><span class="p">:</span> <span class="mf">0.75</span><span class="p">})</span>
                    <span class="c1"># Write logs at every iteration</span>
                    <span class="c1"># Compute average loss</span>
                    <span class="n">avg_cost</span> <span class="o">+=</span> <span class="n">c</span> <span class="o">/</span> <span class="n">total_batch</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Epoch: &quot;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%02d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;  =====&gt; Loss=&quot;</span><span class="p">,</span> <span class="s2">&quot;{:.9f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_cost</span><span class="p">))</span>
                    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: Training :&quot;</span><span class="p">,</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="mf">1.0</span><span class="p">))</span>
                    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: Validation :&quot;</span><span class="p">,</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="mf">1.0</span><span class="p">))</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: Test :&quot;</span><span class="p">,</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="mf">1.0</span><span class="p">))</span>
            <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;Training Finished!&quot;</span><span class="p">)</span>
            <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">file_save</span><span class="p">)</span>
        <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training time =&#39;</span><span class="p">,</span><span class="n">training_time</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># train with AdamOptmiser and learning rate = 0.001</span>

<span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">X_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;lenet5_relu_adam_0_001_128_best&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Start Training!
(&#39;Epoch: &#39;, &#39;10&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.026314799&#39;)
(&#39;Accuracy: Training :&#39;, 0.99590909092643043)
(&#39;Accuracy: Validation :&#39;, 0.98899999999999999)
(&#39;Epoch: &#39;, &#39;20&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.009591126&#39;)
(&#39;Accuracy: Training :&#39;, 0.99758181818181824)
(&#39;Accuracy: Validation :&#39;, 0.98960000000000004)
(&#39;Epoch: &#39;, &#39;30&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.005987098&#39;)
(&#39;Accuracy: Training :&#39;, 0.99834545456279411)
(&#39;Accuracy: Validation :&#39;, 0.99060000000000004)
(&#39;Epoch: &#39;, &#39;40&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.004252277&#39;)
(&#39;Accuracy: Training :&#39;, 0.99934545454545454)
(&#39;Accuracy: Validation :&#39;, 0.99039999999999995)
(&#39;Epoch: &#39;, &#39;50&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003998602&#39;)
(&#39;Accuracy: Training :&#39;, 0.9995090909090909)
(&#39;Accuracy: Validation :&#39;, 0.99099999999999999)
(&#39;Epoch: &#39;, &#39;60&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003078005&#39;)
(&#39;Accuracy: Training :&#39;, 0.99989090909090905)
(&#39;Accuracy: Validation :&#39;, 0.99260000000000004)
(&#39;Epoch: &#39;, &#39;70&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003057050&#39;)
(&#39;Accuracy: Training :&#39;, 0.99952727272727271)
(&#39;Accuracy: Validation :&#39;, 0.99139999999999995)
(&#39;Epoch: &#39;, &#39;80&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003347514&#39;)
(&#39;Accuracy: Training :&#39;, 0.99987272729006682)
(&#39;Accuracy: Validation :&#39;, 0.99099999999999999)
(&#39;Epoch: &#39;, &#39;90&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.002324415&#39;)
(&#39;Accuracy: Training :&#39;, 0.99980000000000002)
(&#39;Accuracy: Validation :&#39;, 0.99239999999999995)
(&#39;Epoch: &#39;, &#39;100&#39;, &#39;  =====&gt; Loss=&#39;, &#39;0.003101566&#39;)
(&#39;Accuracy: Training :&#39;, 0.99987272727272725)
(&#39;Accuracy: Validation :&#39;, 0.99239999999999995)
(&#39;Accuracy: Test :&#39;, 0.99109999999999998)
Training Finished!
(&#39;Training time =&#39;, 2207.5220770835876)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="alert alert-success">

We obtained here a very good accuracy when we applied the dropout layer because the accuracy for validation and test data is very high : more than 99%. So the model doesn't overfit and reaches rapidly a good accuracy. Moreover, the training time is lower than the other ones.

</div>
</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
